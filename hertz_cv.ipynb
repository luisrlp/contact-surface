{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math and Dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "# Machine Learning \n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, KFold\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# import verstack\n",
    "# from verstack.stratified_continuous_split import scsplit\n",
    "\n",
    "# Others\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cu117'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we're working in the directory of this file\n",
    "os.chdir('c:\\\\Users\\\\luisr\\\\OneDrive\\\\Ambiente de Trabalho\\\\Tese\\\\contact-surface')\n",
    "initial_wd = os.getcwd()\n",
    "\n",
    "# Latex fonts\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    # Use 10pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"font.size\": 12,\n",
    "    # Make the legend/label fonts a little smaller\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10\n",
    "}\n",
    "\n",
    "# update to latex fonts\n",
    "plt.rcParams.update(tex_fonts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hertz(i, E, nu, r):\n",
    "    \"\"\"Hertz model for indentation.\n",
    "    \n",
    "    approximation for parabolic indenter.\n",
    "    Parameters\n",
    "    ----------\n",
    "    i : float\n",
    "        Indentation depth.\n",
    "    E : float\n",
    "        Young's modulus.\n",
    "    nu : float\n",
    "        Poisson's ratio.\n",
    "    R : float\n",
    "        Radius of the indenter/probing tip.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Contact force.\n",
    "    \"\"\"\n",
    "    # 'a' and 'factor' calculated based on ref (2)\n",
    "    # search for other formulas to obtain these parameters\n",
    "    a = i/r\n",
    "    factor = 1 - 0.1 * a - (1/840) * a**2 + (11/15120) * a**3 + (1357/6652800) * a**4\n",
    "    force = 4/3 * E / (1 - nu**2) * np.sqrt(r)*i**1.5 * factor\n",
    "    # make nan values zero\n",
    "    force[np.isnan(force)] = 0\n",
    "    return force*10**-6\n",
    "\n",
    "def jkr(i, E, nu, gamma, r):\n",
    "    \"\"\"Johnson-Kendall-Roberts model for indentation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    i : float\n",
    "        Indentation depth.\n",
    "    E : float\n",
    "        Young's modulus.\n",
    "    nu : float\n",
    "        Poisson's ratio.\n",
    "    gamma : float\n",
    "        Surface energy.\n",
    "    R : float\n",
    "        Radius of the indenter.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Contact force.\n",
    "    \"\"\"\n",
    "    E = E * 10**3 # kPa to Pa\n",
    "    i = i * 10**-9 # nm to m\n",
    "    r = r * 10**-9 # nm to m\n",
    "    gamma = gamma * 10**-6 # microJ/m^2 to J/m^2\n",
    "    E_eff = E / (1 - nu**2)\n",
    "    K = 4/3 * E_eff\n",
    "    Ua = np.sqrt(6*np.pi*gamma)\n",
    "    # JKR force formula in (3)\n",
    "    force = K * r **0.5 * i**1.5 - Ua * K**0.5 * r**0.75 * i**0.75\n",
    "    # make nan values zero\n",
    "    force[np.isnan(force)] = 0\n",
    "    # return force*10**-6\n",
    "    return force*10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution of the map\n",
    "res = 200\n",
    "# random values\n",
    "size = res * res\n",
    "\n",
    "# Seed (if needed)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Triangular distrbution\n",
    "E = np.random.triangular(left=0.2, mode=1.8, right=10, size=size)\n",
    "\n",
    "# Poisson's ratio \n",
    "nu = 0.5\n",
    "\n",
    "# surface energy\n",
    "gamma = abs(np.random.uniform(low=1., high=3., size=size))\n",
    "\n",
    "# radius of the indenter\n",
    "r = 1980.0 # (nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"fig, (ax2, ax3) = plt.subplots(1, 2, figsize=(12,4))\\n# ax1.set_xlabel('Time (s)')\\n# ax1.set_ylabel('Displacement')\\n# ax1.plot(t, ramp)\\nax2.set_xlabel('E (kPa)')\\nax2.set_ylabel('Frequency')\\n\\nax2.hist(E, 10, ec='black')\\nax3.set_xlabel('$\\\\gamma$ ($\\\\mu$J/m$^2$)')\\nax3.set_ylabel('Frequency')\\nax3.hist(gamma, 10, ec='black')\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no contact approach. less points\n",
    "#linspace(p1, p2, n_pts)\n",
    "no_contact = np.linspace(-800, 0, 3)\n",
    "\n",
    "'''DISPLACEMENT VECTORS'''\n",
    "xmin, xmax, npts = 0, 150, 50\n",
    "\n",
    "'''Uniformly distributed disp. vectors'''\n",
    "# indentation depth. more points\n",
    "contact = np.linspace(xmin, xmax, npts+1)\n",
    "# approach and withdraw\n",
    "approach = np.concatenate([no_contact[:-1], contact])\n",
    "withdraw = np.flip(approach)\n",
    "ramp = np.concatenate([approach, withdraw])\n",
    "\n",
    "'''Randomly distributed disp. vectors'''\n",
    "# Seed (if needed)\n",
    "np.random.seed(42)\n",
    "\n",
    "rnd_contact_list = [contact]\n",
    "for _ in range(size-1):\n",
    "    aux = np.random.random(npts+1).cumsum()\n",
    "    aux = (aux-aux.min()) / aux.ptp()     #... .ptp(): peak to peak, i.e., xmax-xmin\n",
    "    aux = (xmax-xmin)*aux + xmin\n",
    "    rnd_contact_list.append(aux)\n",
    "rnd_contact = np.array(rnd_contact_list)\n",
    "rnd_approach = np.concatenate([np.repeat([no_contact[:-1]], size, axis=0), rnd_contact], axis=1)\n",
    "rnd_withdraw = np.flip(rnd_approach, axis=1)\n",
    "\n",
    "# define ramp time\n",
    "half_cycle = 2 \n",
    "t_approach = half_cycle*((approach - approach.min(axis=0)) / (approach.max(axis=0) - approach.min(axis=0)))\n",
    "t_withdraw = half_cycle*((withdraw - withdraw.max(axis=0)) / (withdraw.min(axis=0) - withdraw.max(axis=0)))+max(t_approach)\n",
    "t = np.concatenate([t_approach, t_withdraw])\n",
    "# fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(14,4))\n",
    "'''fig, (ax2, ax3) = plt.subplots(1, 2, figsize=(12,4))\n",
    "# ax1.set_xlabel('Time (s)')\n",
    "# ax1.set_ylabel('Displacement')\n",
    "# ax1.plot(t, ramp)\n",
    "ax2.set_xlabel('E (kPa)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "ax2.hist(E, 10, ec='black')\n",
    "ax3.set_xlabel('$\\gamma$ ($\\mu$J/m$^2$)')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.hist(gamma, 10, ec='black')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\AppData\\Local\\Temp\\ipykernel_23812\\566930558.py:25: RuntimeWarning: invalid value encountered in power\n",
      "  force = 4/3 * E / (1 - nu**2) * np.sqrt(r)*i**1.5 * factor\n",
      "C:\\Users\\luisr\\AppData\\Local\\Temp\\ipykernel_23812\\566930558.py:59: RuntimeWarning: invalid value encountered in power\n",
      "  force = K * r **0.5 * i**1.5 - Ua * K**0.5 * r**0.75 * i**0.75\n"
     ]
    }
   ],
   "source": [
    "# construct dataframe\n",
    "df = pd.DataFrame()\n",
    "# 'E' and 'gamma' arrays to list:\n",
    "df['E'] = E.tolist()\n",
    "df['gamma'] = gamma.tolist()\n",
    "# assigns the displacement array for each 'E' (num of E values = len(df) = size)\n",
    "df['approach'] = [rnd_approach[app] for app in range(len(df))]\n",
    "df['withdraw'] = [rnd_withdraw[wd] for wd in range(len(df))]\n",
    "# '..._interp' columns have the sole purpose of allowing the sns errorbar plot \n",
    "df['approach_interp'] = [approach for _ in range(len(df))]\n",
    "df['withdraw_interp'] = [withdraw for _ in range(len(df))]\n",
    "# applies hertz and jkr models to each row (axis= 0(col) or 1(row))\n",
    "    # x will take the values of each row \n",
    "df['f_hertz'] = df.apply(lambda x: hertz(x.approach, x.E, nu, r), axis=1)\n",
    "df['f_jkr'] = df.apply(lambda x: jkr(x.withdraw, x.E, nu, x.gamma, r), axis=1)\n",
    "df['f_hertz_interp'] = df.apply(lambda x: np.interp(x.approach_interp, x.approach, x.f_hertz), axis=1)\n",
    "df['f_jkr_interp'] = df.apply(lambda x: np.interp(-x.withdraw_interp, -x.withdraw, x.f_jkr), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HERTZ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (50,) [  3.   6.   9.  12.  15.  18.  21.  24.  27.  30.  33.  36.  39.  42.\n",
      "  45.  48.  51.  54.  57.  60.  63.  66.  69.  72.  75.  78.  81.  84.\n",
      "  87.  90.  93.  96.  99. 102. 105. 108. 111. 114. 117. 120. 123. 126.\n",
      " 129. 132. 135. 138. 141. 144. 147. 150.]\n"
     ]
    }
   ],
   "source": [
    "#dataframe with contact-only data\n",
    "#df_hc: hertz contact\n",
    "df_hc = pd.DataFrame()\n",
    "df_hc['approach_contact'] = df['approach'].apply(lambda x: x[x>0]) # Para considerar o 0: x>=0\n",
    "df_hc['f_hertz_contact'] = df['f_hertz'].apply(lambda x: x[len(no_contact):]) # len(no_contact)-1\n",
    "df_hc['E_hertz'] = df['E']\n",
    "#df_hc['appproach_contact'] = df.apply(lambda x: x.approach[x.approach>=0], axis=1)\n",
    "#check size of indentation and force vectors\n",
    "print(df_hc['approach_contact'][0].shape, df_hc['f_hertz_contact'][0].shape, df_hc['approach_contact'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2) (40000,)\n"
     ]
    }
   ],
   "source": [
    "x_hc = np.array(df_hc[['approach_contact', 'f_hertz_contact']])\n",
    "y_hc = np.array(df_hc['E_hertz'])\n",
    "print(x_hc.shape, y_hc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into 6 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_input_shape(nparray):\n",
    "    '''\n",
    "    Training and test data from np arrays to torch tensor with desired shape\n",
    "    Input: nparray - numpy array with two dimensions (n_samples, n_features)\n",
    "    Output: torch_tensor - pytorch tensor with 3 dimensions (n_samples, n_pts, n_features) \n",
    "    '''\n",
    "    n_samples = len(nparray)\n",
    "    n_pts = len(nparray[0,0])\n",
    "    torch_tensor = torch.zeros(size=(n_samples, n_pts, 2))\n",
    "    for i in range(n_samples):\n",
    "        aux_nparray = np.hstack((np.array(nparray[i,0]).reshape((n_pts,1)), np.array(nparray[i,1]).reshape((n_pts,1))))\n",
    "        aux_ttensor = torch.from_numpy(aux_nparray).type(torch.float)\n",
    "        torch_tensor[i,:,:] = aux_ttensor\n",
    "    return torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34000, 2),\n",
       " (34000,),\n",
       " array([5.07069319, 7.58736473, 1.80695916, 3.72038722, 2.92083938]),\n",
       " array([[5.07069319],\n",
       "        [7.58736473],\n",
       "        [1.80695916],\n",
       "        [3.72038722],\n",
       "        [2.92083938]]),\n",
       " array([5.07069319, 7.58736473, 1.80695916, 3.72038722, 2.92083938]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratio = 0.15\n",
    "rnd_state = 42\n",
    "\n",
    "# Bins for stratification\n",
    "bin_count = 100\n",
    "bins = pd.qcut(y_hc, bin_count, labels=False, duplicates='drop')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_hc, y_hc, test_size=test_ratio,\n",
    "                                                     random_state=rnd_state, stratify = bins)\n",
    "\n",
    "x_train.shape, y_train.shape, y_train[:5], y_train.reshape(-1,1)[:5], y_train.T[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28333, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28333, 3)\n",
      "(28333, 3)\n",
      "(28333, 3)\n",
      "(28334, 3)\n",
      "(28334, 3)\n",
      "Shape of the test tensors (x, y): (torch.Size([6000, 50, 2]), torch.Size([6000, 1]))\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.15\n",
    "rnd_state = 10\n",
    "\n",
    "# Bins for stratification\n",
    "bin_count = 100\n",
    "bins = pd.qcut(y_hc, bin_count, labels=False, duplicates='drop')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_hc, y_hc, test_size=test_ratio,\n",
    "                                                     random_state=rnd_state, stratify = bins)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=rnd_state)\n",
    "# Continuous target variables -> Categorical bins\n",
    "y_bins = pd.qcut(y_train, bin_count, labels=False, duplicates='drop')\n",
    "# Adds target column to x array (for later division) - UNNECESSARY (???? we can go get directly the information from y_train in the next loop) \n",
    "cv_dataset = np.concatenate((x_train, y_train.reshape(-1,1)),axis=1)\n",
    "\n",
    "train_list, valid_list = [], [] \n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(cv_dataset, y_bins)):\n",
    "    # Extract target values for the current fold\n",
    "    train_fold = cv_dataset[train_index]\n",
    "    print(train_fold.shape)\n",
    "    train_list.append(train_fold)\n",
    "    valid_fold = cv_dataset[test_index]\n",
    "    valid_list.append(valid_fold)\n",
    "\n",
    "# Test data to tensors\n",
    "x_test_t = tensor_input_shape(x_test)\n",
    "y_test_t = torch.from_numpy(y_test).type(torch.float).unsqueeze(dim=1)\n",
    "print(f\"Shape of the test tensors (x, y): {x_test_t.shape, y_test_t.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the split outputs (train, valid): ((28333,), (5667,))\n",
      "These are just the indices of the training and validation instances of the current fold\n",
      "Shape of the training and validation folds: ((28333, 3), (5667, 3))\n",
      "Shape of the training arrays (x, y): ((28333, 2), (28333, 1))\n",
      "Shape of the training tensors (x, y): (torch.Size([28333, 50, 2]), torch.Size([28333, 1]))\n"
     ]
    }
   ],
   "source": [
    "# Do this for each fold in the CV loop\n",
    "\n",
    "train_idx, test_idx = next(skf.split(cv_dataset, y_bins))\n",
    "print(f\"Shape of the split outputs (train, valid): {train_idx.shape, test_idx.shape}\")\n",
    "print(\"These are just the indices of the training and validation instances of the current fold\")\n",
    "train_data = cv_dataset[train_idx]\n",
    "valid_data = cv_dataset[test_idx]\n",
    "print(f\"Shape of the training and validation folds: {train_data.shape, valid_data.shape}\")\n",
    "x_train = train_data[:,:2]\n",
    "y_train = train_data[:,2:].astype(float)\n",
    "print(f\"Shape of the training arrays (x, y): {x_train.shape, y_train.shape}\")\n",
    "x_train_t = tensor_input_shape(x_train)\n",
    "y_train_t = torch.from_numpy(y_train).type(torch.float)\n",
    "print(f\"Shape of the training tensors (x, y): {x_train_t.shape, y_train_t.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28333, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype(float)\n",
    "torch.from_numpy(y_train).type(torch.float).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize target stratification in all folds\n",
    "\n",
    "# Create subplots\n",
    "list_of_arrays = valid_list\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Flatten the axes array to iterate over it easily\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through each array in the list\n",
    "for i, (array, ax) in enumerate(zip(list_of_arrays, axes)):\n",
    "\n",
    "    # Extract the third column of the array\n",
    "    third_column = array[:, 2]\n",
    "\n",
    "    # Plot histogram\n",
    "    ax.hist(third_column, bins=20, edgecolor='black')\n",
    "    ax.set_title(f'Fold {i + 1}')\n",
    "    ax.set_ylim(0, 550)\n",
    "    ax.set_xlabel('$E$ (kPa)')\n",
    "    ax.set_ylabel('Counts')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "def create_model_dir(timestamp, contact_model: str):\n",
    "\n",
    "  ''' Second input must be 'hertz' or 'jkr' '''\n",
    "  \n",
    "  allowed_models = ['hertz', 'jkr']\n",
    "  if contact_model not in allowed_models:\n",
    "    raise ValueError(\"Input value must be one of %s\" % allowed_models)\n",
    "  model_path = 'model_{}'.format(timestamp)\n",
    "  parent_dir = 'c:\\\\Users\\\\luisr\\\\OneDrive\\\\Ambiente de Trabalho\\\\Tese'\n",
    "  if contact_model == 'hertz':\n",
    "    dir = 'Hertz_models'\n",
    "  elif contact_model == 'jkr':\n",
    "    dir = 'JKR_models'\n",
    "  path = os.path.join(parent_dir, dir, model_path)\n",
    "  # path = os.path.join(initial_wd, dir, model_path)\n",
    "  os.mkdir(path)\n",
    "  os.chdir(path)\n",
    "\n",
    "def data_as_pkl(dataset_list: list):\n",
    "  file_names = ['x_train', 'y_train', 'x_valid', 'y_valid', 'x_test', 'y_test']\n",
    "  new_dir = 'Train_Validation_Data'\n",
    "  current_path = os.getcwd()\n",
    "  os.mkdir(new_dir)\n",
    "  os.chdir(new_dir)\n",
    "  for i, array in enumerate(dataset_list):\n",
    "    with open(file_names[i]+'.pkl', 'wb') as f:\n",
    "      pickle.dump(array, f)\n",
    "  os.chdir(current_path)\n",
    "\n",
    "def plot_loss_curve(epochs, mse_training, mse_validation, loss: bool):\n",
    "  plt.ioff()\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  if loss:\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(epochs[0:], mse_training[0:], label=\"Training Loss\")\n",
    "    plt.plot(epochs[0:], mse_validation[0:], label=\"Validation Loss\")\n",
    "  else:\n",
    "    plt.ylabel(\"Error (\\%)\")\n",
    "    plt.plot(epochs[0:], mse_training[0:], label=\"Training Error\")\n",
    "    plt.plot(epochs[0:], mse_validation[0:], label=\"Validation Error\")    \n",
    "  plt.legend()  \n",
    "  # We're not going to plot the first epoch (>>greater loss)\n",
    "  merged_mse_lists = mse_training[1:] + mse_validation[1:]\n",
    "  highest_loss = max(merged_mse_lists)\n",
    "  lowest_loss = min(merged_mse_lists)\n",
    "  delta = highest_loss - lowest_loss\n",
    "  top_of_y_axis = highest_loss + (delta * 0.2)\n",
    "  bottom_of_y_axis = lowest_loss - (delta * 0.2)   \n",
    "  if loss:\n",
    "    plt.yscale('log')\n",
    "    plt.savefig('loss_plot.pdf', bbox_inches='tight') \n",
    "  else:\n",
    "    plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
    "    plt.savefig('error_plot.pdf', bbox_inches='tight')\n",
    "  # plt.show()\n",
    "  plt.close()\n",
    "\n",
    "def plot_error_hist(error_list, test: bool, **kwargs):\n",
    "  plt.ioff()\n",
    "  '''**kwargs: percentage of curves with errors under x%. \n",
    "              The values must be provided for errors in ascending order (error2_5 = y, error10 = z)'''\n",
    "  fig, ax = plt.subplots()\n",
    "  # plt.figure()\n",
    "  x_values = [2.5, 10]\n",
    "  error_values = list(kwargs.values())\n",
    "  ax.hist(error_list, bins=20, density=True, ec='black', range=(0,15)) # to remove outliers, set parameter 'range='\n",
    "  ax.set_xlabel(\"Error $E$ (\\%)\", fontsize=14)\n",
    "  ax.set_ylabel(\"Density\", fontsize=14)\n",
    "  #plt.gca().yaxis.set_major_formatter(PercentFormatter(1)) # set y axis as %\n",
    "  ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "  if test:\n",
    "    ax.axvline(x_values[0], color='red', linestyle='--', label=f'{error_values[0]*100: .1f}\\% of curves with $\\epsilon<2.5\\%$')\n",
    "    ax.axvline(x_values[1], color='green', linestyle='--', label=f'{error_values[1]*100: .1f}\\% of curves with $\\epsilon<10\\%$')\n",
    "    ax.legend(loc='center', ncol=2, bbox_to_anchor=(0.5, 1.05), fontsize=13)\n",
    "    ax.text(0.705, 0.93, 'Experimental test set ($n=24,304$)', transform=ax.transAxes, fontsize=13, ha='center', bbox=dict(boxstyle='round', facecolor='white', edgecolor='black'))\n",
    "    # ax.set_title(\"Test error\")\n",
    "    fig.savefig('error_hist_test.pdf', bbox_inches='tight')\n",
    "  else:\n",
    "    fig.savefig('error_hist_valid.pdf', bbox_inches='tight')\n",
    "  plt.close(fig)\n",
    "\n",
    "  \n",
    "\n",
    "def plot_bad_curves(verror_list, list_inputs, list_labels, test: bool):\n",
    "  plt.ioff()\n",
    "  bad_curves = [(i, j) for i, j in enumerate(verror_list) if j > 15] # Gets index and error value of all errors above 15%\n",
    "  if len(bad_curves) < 5: \n",
    "    all_curves_sorted = sorted([(i, j) for i, j in enumerate(verror_list)], key= lambda k:k[1], reverse=True) # sorts error list, keeping i (the original index of each error value)\n",
    "    for i in range(5-len(bad_curves)):\n",
    "        bad_curves.append(all_curves_sorted[len(bad_curves)+i])\n",
    "  plt.figure()\n",
    "  for j, (i, _) in enumerate(bad_curves):\n",
    "    if j < 5:\n",
    "      tensor_idx = i//len(list_inputs[0])\n",
    "      tensor_fts, tensor_labels = list_inputs[tensor_idx], list_labels[tensor_idx]\n",
    "      plt.plot(tensor_fts[i-tensor_idx*len(list_inputs[0]),:,0].numpy(),\n",
    "              tensor_fts[i-tensor_idx*len(list_inputs[0]),:,1].numpy(),\n",
    "              alpha=0.75,\n",
    "              label=f'E={round(tensor_labels[i-tensor_idx*len(list_inputs[0])].item(),3)} kPa, $\\epsilon$={verror_list[i]: .2f}\\%')\n",
    "  \n",
    "  plt.xlabel('Indentation (nm)')\n",
    "  plt.ylabel('Force (nN)')\n",
    "  plt.legend()\n",
    "  ax = plt.axis()\n",
    "  plt.axis((ax[1],ax[0],ax[2],ax[3]))\n",
    "  if test:\n",
    "    plt.savefig('bad_curves_test.pdf', bbox_inches='tight')\n",
    "  else:\n",
    "    plt.savefig('bad_curves_valid.pdf', bbox_inches='tight')\n",
    "  plt.close()\n",
    "\n",
    "def plot_pred_real_curves(verror_list, list_inputs, list_labels, test: bool, list_predicts, nu, r,exp:bool):\n",
    "  plt.ioff()\n",
    "  bad_curves = []\n",
    "  bad_curves_15 = sorted([(i, j) for i, j in enumerate(verror_list) if j > 15], key= lambda k:k[1], reverse=True)\n",
    "  bad_curves_10 = sorted([(i, j) for i, j in enumerate(verror_list) if j < 10], key= lambda k:k[1], reverse=True)\n",
    "  bad_curves_2 = sorted([(i, j) for i, j in enumerate(verror_list) if j < 2], key= lambda k:k[1], reverse=True)\n",
    "  all_bad_curves = [bad_curves_15, bad_curves_10, bad_curves_2]\n",
    "  for curve in all_bad_curves:\n",
    "    if len(curve) >=1:\n",
    "      bad_curves.append(curve[0])\n",
    "  # plt.figure()\n",
    "  fig, ax = plt.subplots()\n",
    "  colors = ['red','blue', 'green']\n",
    "  line_styles = ['-', ':']\n",
    "  for j, (i, _) in enumerate(bad_curves):\n",
    "    tensor_idx = i//len(list_inputs[0])\n",
    "    tensor_fts, tensor_labels, tensor_predicts = list_inputs[tensor_idx], list_labels[tensor_idx], list_predicts[tensor_idx]\n",
    "    x = tensor_fts[i-tensor_idx*len(list_inputs[0]),:,0].numpy()\n",
    "    y1 = tensor_fts[i-tensor_idx*len(list_inputs[0]),:,1].numpy()\n",
    "    predict = tensor_predicts[i-tensor_idx*len(list_inputs[0])].item()\n",
    "    y2 = hertz(x, predict, nu, r)\n",
    "    ax.plot(x,\n",
    "             y1,\n",
    "             alpha=0.75,\n",
    "             label='$E_{Real}$'+f'={round(tensor_labels[i-tensor_idx*len(list_inputs[0])].item(),1)} kPa, $\\epsilon$={verror_list[i]: .1f} \\%',\n",
    "             color=colors[j], linestyle=line_styles[0])\n",
    "    ax.plot(x,\n",
    "             y2,\n",
    "             color=colors[j], linestyle=line_styles[1])\n",
    "    color_legend = ax.legend()\n",
    "  dummy_lines = []\n",
    "  for k in range(2):\n",
    "      dummy_lines.append(ax.plot([],[], c=\"black\", ls = line_styles[k])[0])\n",
    "  if not exp:\n",
    "    bbox_y = [0.85, 0.79, 0.73]\n",
    "  else:\n",
    "    bbox_y = [0.75, 0.69, 0.64]\n",
    "  linestyle_legend = plt.legend([dummy_lines[i] for i in [0,1]], [\"Real curve\", \"Predicted Curve\"], loc=7, bbox_to_anchor=(1.,bbox_y[len(bad_curves)-1]))\n",
    "  # line_legend = ax.legend(loc='right')\n",
    "  plt.xlabel('Indentation (nm)')\n",
    "  plt.ylabel('Force (nN)')\n",
    "  # plt.legend()\n",
    "  ax.add_artist(color_legend)\n",
    "  ax.add_artist(linestyle_legend)\n",
    "  # put the legends in separate boxes\n",
    "  color_legend.get_frame().set_facecolor('white')\n",
    "  color_legend.get_frame().set_edgecolor('black')\n",
    "  linestyle_legend.get_frame().set_facecolor('white')\n",
    "  linestyle_legend.get_frame().set_edgecolor('black')\n",
    "  # ax.add_artist(line_legend)\n",
    "  ax2 = ax.axis()\n",
    "  ax.axis((ax2[1],ax2[0],ax2[2],ax2[3]))\n",
    "  if test:\n",
    "    fig.savefig('test_pred_vs_real_curves.pdf', bbox_inches='tight')\n",
    "  else:\n",
    "    fig.savefig('valid_pred_vs_real_curves.pdf', bbox_inches='tight')\n",
    "  plt.close()\n",
    "\n",
    "def error_fn(predict_tensor, label_tensor):\n",
    "  '''\n",
    "  INPUTS: * two tensors - true labels and predicts\n",
    "  OUTPUTS: * scalar - mean relative error (in %) between both tensors\n",
    "           * list - relative error (%) for each prediction\n",
    "  '''\n",
    "  error = abs((label_tensor-predict_tensor)/label_tensor*100).squeeze(dim=1).mean().item()\n",
    "  error_list = list(abs((label_tensor-predict_tensor)/label_tensor*100).squeeze(dim=1).detach().numpy())\n",
    "  return error, error_list\n",
    "\n",
    "def plot_error_hist3(error_list, test: bool, **kwargs):\n",
    "  plt.ioff()\n",
    "  '''**kwargs: percentage of curves with errors under x%. \n",
    "              The values must be provided for errors in ascending order (error1 = y, error2_5 = z)'''\n",
    "  fig, ax = plt.subplots()\n",
    "  plt.figure()\n",
    "  x_values = [1, 2.5]\n",
    "  error_values = list(kwargs.values())\n",
    "  ax.hist(error_list, bins=20, density=True, ec='black', range=(0,6)) # to remove outliers, set parameter 'range='\n",
    "  ax.set_xlabel(\"Error $E$ (\\%)\", fontsize=14)\n",
    "  ax.set_ylabel(\"Density\", fontsize=14)\n",
    "  #plt.gca().yaxis.set_major_formatter(PercentFormatter(1)) # set y axis as %\n",
    "  ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "  if test:\n",
    "    ax.axvline(x_values[0], color='red', linestyle='--', label=f'{error_values[0]*100: .1f}\\% of curves with $\\epsilon<1\\%$')\n",
    "    ax.axvline(x_values[1], color='green', linestyle='--', label=f'{error_values[1]*100: .1f}\\% of curves with $\\epsilon<2.5\\%$')\n",
    "    ax.legend(loc='center', ncol=2, bbox_to_anchor=(0.5, 1.05), fontsize=13)\n",
    "    ax.text(0.74, 0.93, f'Synthetic test set ($n=$ {len(error_list)})', transform=ax.transAxes, fontsize=13, ha='center', \n",
    "            bbox=dict(boxstyle='round', facecolor='white', edgecolor='black'))\n",
    "    # ax.set_title(\"Test error\")\n",
    "    fig.savefig('error_hist_test2.pdf', bbox_inches='tight')\n",
    "  else:\n",
    "    fig.savefig('error_hist_valid_2.pdf', bbox_inches='tight')\n",
    "  plt.close(fig)\n",
    "  # plt.show()\n",
    "\n",
    "def scatter_true_pred(list_labels, list_preds, set: int, exp: bool):\n",
    "  '''Scatter plot of model predictions vs true outputs around a unitary slope line\n",
    "    list_labels and list_preds: lists of one-valued tensors\n",
    "    set: 0 - Validation, 1 - Test synthetic, 2 - Test experimental'''\n",
    "  plt.ioff()\n",
    "  if set == 2:\n",
    "    labels_array = np.array([tensor.item() for tensor in list_labels])\n",
    "    predicts_array = np.array([tensor.item() for tensor in list_preds])\n",
    "  else:\n",
    "    labels_array = np.array(list_labels[0].squeeze(dim=1).detach())\n",
    "    predicts_array = np.array(list_preds[0].squeeze(dim=1).detach())\n",
    "  if exp:\n",
    "    x = np.linspace(0,5.5,100)\n",
    "  else:\n",
    "    x = np.linspace(0,10.2,100)\n",
    "  plt.plot(x,x, color='orange', linewidth=2, label=\"Ideal predictions\", alpha=0.8)\n",
    "  plt.scatter(labels_array, predicts_array, alpha=0.5, edgecolors='black', label=f\"Observations ($n = 6000$)\")\n",
    "  plt.legend(fontsize=14)\n",
    "  plt.xlabel(\"True $E$ (kPa)\")\n",
    "  plt.ylabel(\"Predicted $E$ (kPa)\")\n",
    "  sets = ['valid', 'test_syn', 'test_exp']\n",
    "  if exp:\n",
    "    plt.xlim(0,5.5)\n",
    "    plt.ylim(0,5.5)\n",
    "    plt.savefig('scatter_' + sets[set] + '_5' + '.pdf', bbox_inches='tight')\n",
    "  else:\n",
    "    plt.xlim(0,10.2)\n",
    "    plt.ylim(0,10.2)\n",
    "    plt.savefig('scatter_' + sets[set] + '.pdf', bbox_inches='tight')\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hertz_Dataset():\n",
    "  \n",
    "  def __init__(self,features,labels):\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.features[idx],self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataloader\n",
    "test_data = Hertz_Dataset(x_test_t, y_test_t)\n",
    "test_loader=DataLoader(test_data,batch_size=len(test_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24304, 2) (24304,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare experimental data\n",
    "df_exp = pd.read_pickle(\"df_final.pkl\")\n",
    "x_test_exp = np.array(df_exp[['ind', 'force']])\n",
    "y_test_exp = np.array(df_exp['ehertz'])\n",
    "print(x_test_exp.shape, y_test_exp.shape)\n",
    "\n",
    "x_test_exp_t = tensor_input_shape(x_test_exp)\n",
    "y_test_exp_t = torch.from_numpy(y_test_exp.astype(float)).type(torch.float).unsqueeze(dim=1)\n",
    "\n",
    "test_exp_data = Hertz_Dataset(x_test_exp_t, y_test_exp_t)\n",
    "test_exp_loader=DataLoader(test_exp_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ After changing one of the hyperparameters: ########################\n",
    "### Re-run the cells where the model class and the model_params dict are defined ###\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "LEARNING_RATE = 2.296e-4 # 2.296e-4\n",
    "EPOCHS = 80 # 80\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Size of each layer\n",
    "HIDDEN_UNITS_1 = 256 # 256\n",
    "HIDDEN_UNITS_2 = 256 # 256\n",
    "HIDDEN_UNITS_3 = 32 # 32\n",
    "\n",
    "# 1: 2 layers, 2: 3 layers\n",
    "ARCHITECTURE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataloader(dataset, train_ids, test_ids):\n",
    "    train_data = dataset[train_ids]\n",
    "    valid_data = dataset[test_ids]\n",
    "    x_train = train_data[:,:2]\n",
    "    y_train = train_data[:,2:].astype(float)\n",
    "    x_valid = valid_data[:,:2]\n",
    "    y_valid = valid_data[:,2:].astype(float)\n",
    "    x_train_t = tensor_input_shape(x_train)\n",
    "    y_train_t = torch.from_numpy(y_train).type(torch.float)\n",
    "    x_valid_t = tensor_input_shape(x_valid)\n",
    "    y_valid_t = torch.from_numpy(y_valid).type(torch.float)\n",
    "    train_data = Hertz_Dataset(x_train_t, y_train_t)\n",
    "    valid_data = Hertz_Dataset(x_valid_t, y_valid_t)\n",
    "    train_loader=DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=False)\n",
    "    valid_loader=DataLoader(valid_data, batch_size=len(valid_data), shuffle=False)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regression model\n",
    "class Regression_Hertz(nn.Module):\n",
    "    def __init__(self, input_shape, HIDDEN_UNITS_1, HIDDEN_UNITS_2, HIDDEN_UNITS_3):\n",
    "        super(Regression_Hertz, self).__init__()\n",
    "        input_size = input_shape[0] * input_shape[1]\n",
    "        self.layers = nn.Sequential(nn.Flatten(),\n",
    "                                    nn.Linear(input_size, HIDDEN_UNITS_1),\n",
    "                                    nn.LeakyReLU(), # Change model parameters and in draft.py\n",
    "                                    nn.Linear(HIDDEN_UNITS_1,HIDDEN_UNITS_2),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Linear(HIDDEN_UNITS_2, HIDDEN_UNITS_3),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Linear(HIDDEN_UNITS_3, 1))\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "    \n",
    "# Define input shape\n",
    "input_shape = x_train_t.shape[1:]\n",
    "# Instantiate the model (add these two lines at the beggining of each fold cycle)\n",
    "torch.manual_seed(42)\n",
    "model_Hertz = Regression_Hertz(input_shape, HIDDEN_UNITS_1, HIDDEN_UNITS_2, HIDDEN_UNITS_3)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.HuberLoss()\n",
    "optimizer = torch.optim.Adam(model_Hertz.parameters(), \n",
    "                            lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, train_loader, optimizer): # (epoch_index, tb_writer)\n",
    "    # running_loss = 0.\n",
    "    # last_loss = 0.\n",
    "    loss_list = []\n",
    "    error_list = []\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_Hertz(inputs)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        error, _ = error_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        # Gather data and report\n",
    "        loss_list.append(loss.item())\n",
    "        error_list.append(error)\n",
    "        # running_loss += loss.item()  # .item() converts tensor to number\n",
    "        # print(i, loss.item())\n",
    "    return loss_list, error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'Epochs': EPOCHS, \n",
    "                'Learning Rate': LEARNING_RATE,\n",
    "                'Batch Size': BATCH_SIZE,\n",
    "                'Number of Hidden layers': ARCHITECTURE+1,\n",
    "                'Type of layers': nn.Linear,\n",
    "                'Activation function': nn.LeakyReLU(),\n",
    "                'Architecture': ARCHITECTURE,\n",
    "                'Hidden Units 1': HIDDEN_UNITS_1,\n",
    "                'Hidden Units 2': HIDDEN_UNITS_2,\n",
    "                'Hidden Units 3': HIDDEN_UNITS_3,\n",
    "                'Input shape': list(input_shape),\n",
    "                'Loss function': loss_fn,\n",
    "                'Optimizer': optimizer,\n",
    "                'nu': nu,\n",
    "                'radius': r,\n",
    "                'xmax': xmax}\n",
    "# model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_Hertz(EPOCHS: int,\n",
    "                      model,\n",
    "                      tloader,\n",
    "                      vloader,\n",
    "                      loss_fn,\n",
    "                      optimizer,\n",
    "                      x_test_t, y_test_t\n",
    "                      ):\n",
    "    plt.ioff()\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    # Set new directory for new model\n",
    "    # initial_wd = os.getcwd()\n",
    "    create_model_dir(timestamp, contact_model='hertz')\n",
    "    best_vloss = 1_000_000.\n",
    "    cols = ['Epoch', 'Train Loss', 'Mean Train Loss', 'Mean Val Loss', 'Train Error (%)', 'Mean Train Error (%)', 'Mean Val Error (%)']\n",
    "    row = []\n",
    "    # start timer counter\n",
    "    start = datetime.now()\n",
    "    for epoch in range(EPOCHS):\n",
    "        # print('EPOCH {}:'.format(epoch + 1))\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        loss_list, error_list = train_one_epoch(epoch, tloader, optimizer) # (epoch, writer)\n",
    "        # We don't need gradients on to do reporting\n",
    "        model.train(False)\n",
    "        running_vloss = 0.0\n",
    "        running_verror = 0.0\n",
    "        verror_list, fts_list, labels_list, predicts_list = [], [], [], []\n",
    "        for i, vdata in enumerate(vloader):\n",
    "            vinputs, vlabels = vdata\n",
    "            fts_list.append(vinputs)\n",
    "            labels_list.append(vlabels)\n",
    "            voutputs = model(vinputs)\n",
    "            predicts_list.append(voutputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            verror, verror_aux_list = error_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "            running_verror += verror\n",
    "            verror_list += verror_aux_list\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        avg_verror = running_verror / (i + 1)\n",
    "        # print(f\"Validation error in epoch {epoch+1}: {np.array(loss_list).mean():.3f}\") ###~\n",
    "        row.append(dict(zip(cols, \n",
    "                            [epoch+1, \n",
    "                            loss_list, \n",
    "                            np.array(loss_list).mean(), \n",
    "                            avg_vloss.item(), \n",
    "                            error_list, \n",
    "                            np.array(error_list).mean(), \n",
    "                            avg_verror])))\n",
    "        # Track best performance\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            best_verror = avg_verror\n",
    "            model_path = 'model_state_dict_{}_{}.pt'.format(timestamp, epoch+1)\n",
    "            #torch.save(model.state_dict(), model_path)\n",
    "            verror_list_best = verror_list\n",
    "            fts_list_best = fts_list\n",
    "            labels_list_best = labels_list\n",
    "            predicts_list_best = predicts_list\n",
    "    end = datetime.now()\n",
    "    model_params['Training Time'] = end - start\n",
    "    print('Training time: {}'.format(model_params['Training Time']))\n",
    "    print(f\"Validation error (%): {best_verror}\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    model_params['Model Path'] = model_path\n",
    "    df = pd.DataFrame(row)\n",
    "    df.to_csv('loss_error.csv', index=False)\n",
    "    # plot_loss_curve(df['Epoch'].values.tolist(), df['Mean Train Loss'].values.tolist(), df['Mean Val Loss'].values.tolist(), loss=True)\n",
    "    # plot_loss_curve(df['Epoch'].values.tolist(), df['Mean Train Error (%)'].values.tolist(), df['Mean Val Error (%)'].values.tolist(), loss=False)\n",
    "    # plot_bad_curves(verror_list_best, fts_list_best, labels_list_best, test=False)\n",
    "    # plot_pred_real_curves(verror_list_best, fts_list_best, labels_list_best, test=False, list_predicts=predicts_list_best, nu=nu, r=r)\n",
    "    # plot_error_hist(verror_list_best, test=False)\n",
    "    scatter_true_pred(labels_list_best, predicts_list_best, set = 0, exp=True)\n",
    "    scatter_true_pred(labels_list_best, predicts_list_best, set = 0, exp=False)\n",
    "    with open('model_params.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = model_params.keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerow(model_params)\n",
    "    torch.save(x_test_t, 'x_test_t.pt')\n",
    "    torch.save(y_test_t, 'y_test_t.pt')\n",
    "    # os.chdir(initial_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model: nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: nn.Module,\n",
    "               error_fn):\n",
    "    model.eval()\n",
    "    loss, error = 0, 0\n",
    "    error_list, fts_list, labels_list, predicts_list = [], [], [], []\n",
    "    with torch.inference_mode():\n",
    "        for i, testdata in enumerate(data_loader):\n",
    "            test_fts, test_labels = testdata\n",
    "            fts_list.append(test_fts)\n",
    "            labels_list.append(test_labels)\n",
    "            y_pred = model(test_fts)\n",
    "            predicts_list.append(y_pred)\n",
    "            loss += loss_fn(y_pred, test_labels) \n",
    "            error_aux, error_list_aux = error_fn(y_pred, test_labels)\n",
    "            error += error_aux\n",
    "            error_list += error_list_aux\n",
    "        loss /= len(data_loader)\n",
    "        error /= len(data_loader)\n",
    "    np.save('error_list_test_syn.npy', np.array(error_list))\n",
    "    error1 = len([i for i in error_list if i <= 1])/len(error_list)\n",
    "    error2_5 = len([i for i in error_list if i <= 2.5])/len(error_list)\n",
    "    error5 = len([i for i in error_list if i <= 5])/len(error_list)\n",
    "    error10 = len([i for i in error_list if i <= 10])/len(error_list)\n",
    "    print(f\"Test Error (%): {error}\")\n",
    "    print(f\"Test Curves under 5% (%): {error5*100}\")\n",
    "    results_dict = {\"model_name\": model.__class__.__name__,\n",
    "                    \"model_loss\": loss.item(),\n",
    "                    \"model_error\": error,\n",
    "                    \"under_1%_error\": error1,\n",
    "                    \"under_2.5%_error\": error2_5,\n",
    "                    \"under_5%_error\": error5,\n",
    "                    \"under_10%_error\": error10}\n",
    "    \n",
    "    with open('test_results.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = results_dict.keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerow(results_dict)\n",
    "    plot_error_hist(error_list, test=True, error1=error2_5, error2=error10)\n",
    "    plot_error_hist3(error_list, test=True, error1=error1, error2=error2_5)\n",
    "    plot_bad_curves(error_list, fts_list, labels_list, test=True)\n",
    "    plot_pred_real_curves(error_list, fts_list, labels_list, test=True, list_predicts=predicts_list, nu=nu, r=r, exp=False)\n",
    "    scatter_true_pred(labels_list, predicts_list, set=1, exp=True)\n",
    "    scatter_true_pred(labels_list, predicts_list, set=1, exp=False)\n",
    "    print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_experimental(model: nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: nn.Module,\n",
    "               error_fn):\n",
    "    # create a folder if it doesn't exist yet\n",
    "    exp_dir = 'Test_Experimental'\n",
    "    if not os.path.exists(exp_dir):     \n",
    "        os.mkdir(exp_dir)\n",
    "    os.chdir(exp_dir)\n",
    "    model.eval()\n",
    "    loss, error = 0, 0\n",
    "    error_list, fts_list, labels_list, predicts_list, predicts_list2 = [], [], [], [], [] # pred_list2 is the list of predictions with only tensor items\n",
    "    with torch.inference_mode():\n",
    "        for i, testdata in enumerate(data_loader):\n",
    "            test_fts, test_labels = testdata\n",
    "            fts_list.append(test_fts)\n",
    "            labels_list.append(test_labels)\n",
    "            y_pred = model(test_fts)\n",
    "            predicts_list.append(y_pred)\n",
    "            predicts_list2.append(y_pred.item())\n",
    "            loss += loss_fn(y_pred, test_labels) \n",
    "            error_aux, error_list_aux = error_fn(y_pred, test_labels)\n",
    "            error += error_aux\n",
    "            error_list += error_list_aux\n",
    "        loss /= len(data_loader)\n",
    "        error /= len(data_loader)\n",
    "    error1 = len([i for i in error_list if i <= 1])/len(error_list)\n",
    "    error2_5 = len([i for i in error_list if i <= 2.5])/len(error_list)\n",
    "    error5 = len([i for i in error_list if i <= 5])/len(error_list)\n",
    "    error10 = len([i for i in error_list if i <= 10])/len(error_list)\n",
    "    print(f\"Test Error (%): {error}\")\n",
    "    print(f\"Test Curves under 10% (%): {error10*100}\")\n",
    "    print(f\"Test Curves under 5% (%): {error5*100}\")\n",
    "    np.save('error_list.npy', np.array(error_list))\n",
    "    np.save('predicts_list.npy', np.array(predicts_list2))\n",
    "    results_dict = {\"model_name\": model.__class__.__name__,\n",
    "                    \"model_loss\": loss.item(),\n",
    "                    \"model_error\": error,\n",
    "                    \"under_1%_error\": error1,\n",
    "                    \"under_2.5%_error\": error2_5,\n",
    "                    \"under_5%_error\": error5,\n",
    "                    \"under_10%_error\": error10,\n",
    "                    \"total_curves\": len(error_list)}\n",
    "    \n",
    "    with open('test_results.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = results_dict.keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerow(results_dict)\n",
    "    plot_error_hist(error_list, test=True, error1=error2_5, error2=error10)\n",
    "    plot_bad_curves(error_list, fts_list, labels_list, test=True)\n",
    "    plot_pred_real_curves(error_list, fts_list, labels_list, test=True, list_predicts=predicts_list, nu=nu, r=r, exp=False)\n",
    "    scatter_true_pred(labels_list, predicts_list, set = 2, exp=True)\n",
    "    print(results_dict)\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Training time: 0:09:55.123312\n",
      "Validation error (%): 0.32851526141166687\n",
      "Testing on synthetic data...\n",
      "Test Error (%): 0.9723677635192871\n",
      "Test Curves under 5% (%): 98.83333333333333\n",
      "{'model_name': 'Regression_Hertz', 'model_loss': 0.0003300985263194889, 'model_error': 0.9723677635192871, 'under_1%_error': 0.6621666666666667, 'under_2.5%_error': 0.9348333333333333, 'under_5%_error': 0.9883333333333333, 'under_10%_error': 0.999}\n",
      "Testing on experimental data...\n",
      "Test Error (%): 5.168417516107936\n",
      "Test Curves under 10% (%): 85.94058591178407\n",
      "Test Curves under 5% (%): 61.07636603028308\n",
      "{'model_name': 'Regression_Hertz', 'model_loss': 0.007981432601809502, 'model_error': 5.168417516107936, 'under_1%_error': 0.15211487820934824, 'under_2.5%_error': 0.36109282422646477, 'under_5%_error': 0.6107636603028308, 'under_10%_error': 0.8594058591178407, 'total_curves': 24304}\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "FOLD 6\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Perform Cross-Validation ()\n",
    "plt.ioff() # Turn off plotting display\n",
    "k_folds = 6 # 6\n",
    "\n",
    "# Stratified K-fold cross validator\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=14)\n",
    "\n",
    "# Start print\n",
    "print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids, valid_ids) in enumerate(skf.split(cv_dataset, y_bins)):\n",
    "    os.chdir(initial_wd)\n",
    "    # Prints\n",
    "    print(f'FOLD {fold+1}')\n",
    "    print('--------------------------------')\n",
    "    if fold == 2:\n",
    "        # Dataset and DataLoader stuff\n",
    "        train_loader, valid_loader = prep_dataloader(dataset=cv_dataset, train_ids=train_ids, test_ids=valid_ids)            \n",
    "\n",
    "        # Initialize the NN\n",
    "        input_shape = x_train_t.shape[1:]\n",
    "        torch.manual_seed(42)\n",
    "        model_Hertz = Regression_Hertz(input_shape, HIDDEN_UNITS_1, HIDDEN_UNITS_2, HIDDEN_UNITS_3)\n",
    "        optimizer = torch.optim.Adam(model_Hertz.parameters(), \n",
    "                                lr=LEARNING_RATE)\n",
    "        # Start Training + Validation\n",
    "        print(\"Training ...\")\n",
    "        plt.ioff()\n",
    "        train_model_Hertz(EPOCHS, model_Hertz, train_loader, valid_loader, loss_fn, optimizer, x_test_t, y_test_t)\n",
    "        \n",
    "        # Start testing\n",
    "        print(\"Testing on synthetic data...\")\n",
    "        eval_model(model_Hertz, test_loader, loss_fn, error_fn)\n",
    "        print(\"Testing on experimental data...\")\n",
    "        eval_model_experimental(model_Hertz, test_exp_loader, loss_fn, error_fn)\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\luisr\\\\OneDrive\\\\Ambiente de Trabalho\\\\Tese\\\\contact-surface'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(initial_wd)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
