{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math and Dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "# Machine Learning \n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, KFold\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# import verstack\n",
    "# from verstack.stratified_continuous_split import scsplit\n",
    "\n",
    "# Others\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we're working in the directory of this file\n",
    "os.chdir('c:\\\\Users\\\\luisr\\\\OneDrive\\\\Ambiente de Trabalho\\\\Tese\\\\contact-surface')\n",
    "initial_wd = os.getcwd()\n",
    "\n",
    "# Latex fonts\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    # Use 10pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"font.size\": 12,\n",
    "    # Make the legend/label fonts a little smaller\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10\n",
    "}\n",
    "\n",
    "# update to latex fonts\n",
    "plt.rcParams.update(tex_fonts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hertz(i, E, nu, r):\n",
    "    \"\"\"Hertz model for indentation.\n",
    "    \n",
    "    approximation for parabolic indenter.\n",
    "    Parameters\n",
    "    ----------\n",
    "    i : float\n",
    "        Indentation depth.\n",
    "    E : float\n",
    "        Young's modulus.\n",
    "    nu : float\n",
    "        Poisson's ratio.\n",
    "    R : float\n",
    "        Radius of the indenter/probing tip.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Contact force.\n",
    "    \"\"\"\n",
    "    # 'a' and 'factor' calculated based on ref (2)\n",
    "    # search for other formulas to obtain these parameters\n",
    "    a = i/r\n",
    "    factor = 1 - 0.1 * a - (1/840) * a**2 + (11/15120) * a**3 + (1357/6652800) * a**4\n",
    "    force = 4/3 * E / (1 - nu**2) * np.sqrt(r)*i**1.5 * factor\n",
    "    # make nan values zero\n",
    "    force[np.isnan(force)] = 0\n",
    "    return force*10**-6\n",
    "\n",
    "def jkr(i, E, nu, gamma, r):\n",
    "    \"\"\"Johnson-Kendall-Roberts model for indentation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    i : float\n",
    "        Indentation depth.\n",
    "    E : float\n",
    "        Young's modulus.\n",
    "    nu : float\n",
    "        Poisson's ratio.\n",
    "    gamma : float\n",
    "        Surface energy.\n",
    "    R : float\n",
    "        Radius of the indenter.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Contact force.\n",
    "    \"\"\"\n",
    "    E = E * 10**3 # kPa to Pa\n",
    "    i = i * 10**-9 # nm to m\n",
    "    r = r * 10**-9 # nm to m\n",
    "    gamma = gamma * 10**-6 # microJ/m^2 to J/m^2\n",
    "    E_eff = E / (1 - nu**2)\n",
    "    K = 4/3 * E_eff\n",
    "    Ua = np.sqrt(6*np.pi*gamma)\n",
    "    # JKR force formula in (3)\n",
    "    force = K * r **0.5 * i**1.5 - Ua * K**0.5 * r**0.75 * i**0.75\n",
    "    # make nan values zero\n",
    "    force[np.isnan(force)] = 0\n",
    "    # return force*10**-6\n",
    "    return force*10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution of the map\n",
    "res = 200\n",
    "# random values\n",
    "size = res * res\n",
    "\n",
    "# Seed (if needed)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Triangular distrbution\n",
    "E = np.random.triangular(left=0.2, mode=1.8, right=10, size=size)\n",
    "\n",
    "# Poisson's ratio \n",
    "nu = 0.5\n",
    "\n",
    "# surface energy\n",
    "gamma = abs(np.random.uniform(low=1., high=3., size=size))\n",
    "\n",
    "# radius of the indenter\n",
    "r = 1980.0 # (nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no contact approach. less points\n",
    "#linspace(p1, p2, n_pts)\n",
    "no_contact = np.linspace(-800, 0, 3)\n",
    "\n",
    "'''DISPLACEMENT VECTORS'''\n",
    "xmin, xmax, npts = 0, 150, 50\n",
    "\n",
    "'''Uniformly distributed disp. vectors'''\n",
    "# indentation depth. more points\n",
    "contact = np.linspace(xmin, xmax, npts+1)\n",
    "# approach and withdraw\n",
    "approach = np.concatenate([no_contact[:-1], contact])\n",
    "withdraw = np.flip(approach)\n",
    "ramp = np.concatenate([approach, withdraw])\n",
    "\n",
    "'''Randomly distributed disp. vectors'''\n",
    "# Seed (if needed)\n",
    "np.random.seed(42)\n",
    "\n",
    "rnd_contact_list = [contact]\n",
    "for _ in range(size-1):\n",
    "    aux = np.random.random(npts+1).cumsum()\n",
    "    aux = (aux-aux.min()) / aux.ptp()     #... .ptp(): peak to peak, i.e., xmax-xmin\n",
    "    aux = (xmax-xmin)*aux + xmin\n",
    "    rnd_contact_list.append(aux)\n",
    "rnd_contact = np.array(rnd_contact_list)\n",
    "rnd_approach = np.concatenate([np.repeat([no_contact[:-1]], size, axis=0), rnd_contact], axis=1)\n",
    "rnd_withdraw = np.flip(rnd_approach, axis=1)\n",
    "\n",
    "# define ramp time\n",
    "half_cycle = 2 \n",
    "t_approach = half_cycle*((approach - approach.min(axis=0)) / (approach.max(axis=0) - approach.min(axis=0)))\n",
    "t_withdraw = half_cycle*((withdraw - withdraw.max(axis=0)) / (withdraw.min(axis=0) - withdraw.max(axis=0)))+max(t_approach)\n",
    "t = np.concatenate([t_approach, t_withdraw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisr\\AppData\\Local\\Temp\\ipykernel_19468\\566930558.py:25: RuntimeWarning: invalid value encountered in power\n",
      "  force = 4/3 * E / (1 - nu**2) * np.sqrt(r)*i**1.5 * factor\n",
      "C:\\Users\\luisr\\AppData\\Local\\Temp\\ipykernel_19468\\566930558.py:59: RuntimeWarning: invalid value encountered in power\n",
      "  force = K * r **0.5 * i**1.5 - Ua * K**0.5 * r**0.75 * i**0.75\n"
     ]
    }
   ],
   "source": [
    "# construct dataframe\n",
    "df = pd.DataFrame()\n",
    "# 'E' and 'gamma' arrays to list:\n",
    "df['E'] = E.tolist()\n",
    "df['gamma'] = gamma.tolist()\n",
    "# assigns the displacement array for each 'E' (num of E values = len(df) = size)\n",
    "df['approach'] = [rnd_approach[app] for app in range(len(df))]\n",
    "df['withdraw'] = [rnd_withdraw[wd] for wd in range(len(df))]\n",
    "# '..._interp' columns have the sole purpose of allowing the sns errorbar plot \n",
    "df['approach_interp'] = [approach for _ in range(len(df))]\n",
    "df['withdraw_interp'] = [withdraw for _ in range(len(df))]\n",
    "# applies hertz and jkr models to each row (axis= 0(col) or 1(row))\n",
    "    # x will take the values of each row \n",
    "df['f_hertz'] = df.apply(lambda x: hertz(x.approach, x.E, nu, r), axis=1)\n",
    "df['f_jkr'] = df.apply(lambda x: jkr(x.withdraw, x.E, nu, x.gamma, r), axis=1)\n",
    "df['f_hertz_interp'] = df.apply(lambda x: np.interp(x.approach_interp, x.approach, x.f_hertz), axis=1)\n",
    "df['f_jkr_interp'] = df.apply(lambda x: np.interp(-x.withdraw_interp, -x.withdraw, x.f_jkr), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **JKR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (50,)\n"
     ]
    }
   ],
   "source": [
    "#df_jkr: dataframe for jkr data\n",
    "df_jkr = pd.DataFrame()\n",
    "df_jkr['withdraw'] = df['withdraw'].copy()\n",
    "df_jkr['withdraw_contact'] = df_jkr['withdraw'].copy().apply(lambda x: x[x>0])\n",
    "df_jkr['f_jkr'] = df['f_jkr'].copy()\n",
    "df_jkr['f_jkr_contact'] = df_jkr['f_jkr'].copy().apply(lambda x: x[:-(len(no_contact))])\n",
    "df_jkr['E_jkr'] = df['E'].copy()\n",
    "df_jkr['gamma_jkr'] = df['gamma'].copy()\n",
    "\n",
    "#check size of indentation and force vectors\n",
    "print(df_jkr['withdraw_contact'][0].shape, df_jkr['f_jkr_contact'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                            withdraw  \\\n",
       " 0  [150.0, 147.0, 144.0, 141.0, 138.0, 135.0, 132...   \n",
       " 1  [150.0, 143.64657852132757, 142.4352780999585,...   \n",
       " 2  [150.0, 145.96271699783, 145.76333541182936, 1...   \n",
       " 3  [150.0, 149.10283749624375, 147.6195141561324,...   \n",
       " 4  [150.0, 144.79045779182758, 143.8533839693698,...   \n",
       " \n",
       "                                     withdraw_contact  \\\n",
       " 0  [150.0, 147.0, 144.0, 141.0, 138.0, 135.0, 132...   \n",
       " 1  [150.0, 143.64657852132757, 142.4352780999585,...   \n",
       " 2  [150.0, 145.96271699783, 145.76333541182936, 1...   \n",
       " 3  [150.0, 149.10283749624375, 147.6195141561324,...   \n",
       " 4  [150.0, 144.79045779182758, 143.8533839693698,...   \n",
       " \n",
       "                                                f_jkr  \\\n",
       " 0  [0.26414709113338425, 0.25391007093358003, 0.2...   \n",
       " 1  [0.9367124928571328, 0.870804937256369, 0.8584...   \n",
       " 2  [0.5880142576844827, 0.5606480463863339, 0.559...   \n",
       " 3  [0.4493295633329905, 0.4445061259459816, 0.436...   \n",
       " 4  [0.1403291245805178, 0.13012597683803337, 0.12...   \n",
       " \n",
       "                                        f_jkr_contact     E_jkr  gamma_jkr  \n",
       " 0  [0.26414709113338425, 0.25391007093358003, 0.2...  2.910433   1.597824  \n",
       " 1  [0.9367124928571328, 0.870804937256369, 0.8584...  8.009875   1.189636  \n",
       " 2  [0.5880142576844827, 0.5606480463863339, 0.559...  5.359206   1.252718  \n",
       " 3  [0.4493295633329905, 0.4445061259459816, 0.436...  4.320933   1.361342  \n",
       " 4  [0.1403291245805178, 0.13012597683803337, 0.12...  1.764088   1.407307  ,\n",
       " None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jkr.head(), print(len(df_jkr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"x_jkr = np.array(df_jkr[['withdraw_contact', 'f_jkr_contact']])\\ny_jkr = np.array(df_jkr[['E_jkr','gamma_jkr']])\\nprint(x_jkr.shape, y_jkr.shape)\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x_jkr = np.array(df_jkr[['withdraw_contact', 'f_jkr_contact']])\n",
    "y_jkr = np.array(df_jkr[['E_jkr','gamma_jkr']])\n",
    "print(x_jkr.shape, y_jkr.shape)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into 6 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_input_shape(nparray):\n",
    "    '''\n",
    "    Training and test data from np arrays to torch tensor with desired shape\n",
    "    Input: nparray - numpy array with two dimensions (n_samples, n_features)\n",
    "    Output: torch_tensor - pytorch tensor with 3 dimensions (n_samples, n_pts, n_features) \n",
    "    '''\n",
    "    n_samples = len(nparray)\n",
    "    n_pts = len(nparray[0,0])\n",
    "    torch_tensor = torch.zeros(size=(n_samples, n_pts, 2))\n",
    "    for i in range(n_samples):\n",
    "        aux_nparray = np.hstack((np.array(nparray[i,0]).reshape((n_pts,1)), np.array(nparray[i,1]).reshape((n_pts,1))))\n",
    "        aux_ttensor = torch.from_numpy(aux_nparray).type(torch.float)\n",
    "        torch_tensor[i,:,:] = aux_ttensor\n",
    "    return torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisr\\OneDrive\\Ambiente de Trabalho\\Tese\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=6.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n",
      "Split 2\n",
      "Split 3\n",
      "Split 4\n",
      "Split 5\n",
      "Split 6\n",
      "Shape of the test tensors (x, y): (torch.Size([6000, 50, 2]), torch.Size([6000, 2]))\n"
     ]
    }
   ],
   "source": [
    "test_ratio = 0.15\n",
    "rnd_state = None\n",
    "\n",
    "target_cols = ['E_jkr_cat', 'gamma_jkr_cat']\n",
    "nbins = 30\n",
    "\n",
    "# Training-Test Split\n",
    "while nbins >= 1:\n",
    "    print(nbins)\n",
    "    try:\n",
    "        df_jkr['E_jkr_cat'] = pd.cut(df_jkr['E_jkr'], bins=nbins)\n",
    "        df_jkr['gamma_jkr_cat'] = pd.cut(df_jkr['gamma_jkr'], bins=nbins)\n",
    "        train_df_jkr, test_df_jkr = train_test_split(df_jkr, test_size=test_ratio, \n",
    "                                             stratify=df_jkr[target_cols], random_state=rnd_state)\n",
    "        break\n",
    "    except:\n",
    "        nbins += -1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=rnd_state)\n",
    "# Combine categorical target variables into one column\n",
    "train_df_jkr['combined_targets'] = train_df_jkr['E_jkr_cat'].astype(str) + '_' + train_df_jkr['gamma_jkr_cat'].astype(str)\n",
    "\n",
    "train_list, valid_list = [], []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train_df_jkr, train_df_jkr['combined_targets'])):\n",
    "    print(f\"Split {i+1}\")\n",
    "    # Extract target values for the current fold\n",
    "    train_fold = np.array(train_df_jkr[['withdraw_contact', 'f_jkr_contact','E_jkr', 'gamma_jkr']].iloc[train_index])\n",
    "    train_list.append(train_fold)\n",
    "    valid_fold = np.array(train_df_jkr[['withdraw_contact', 'f_jkr_contact','E_jkr', 'gamma_jkr']].iloc[test_index])\n",
    "    valid_list.append(valid_fold)\n",
    "\n",
    "# Test data to tensors\n",
    "ft_cols = ['withdraw_contact', 'f_jkr_contact']\n",
    "lb_cols = ['E_jkr', 'gamma_jkr']\n",
    "x_test_jkr = np.array(test_df_jkr[ft_cols])\n",
    "y_test_jkr = np.array(test_df_jkr[lb_cols])\n",
    "x_test_t_jkr = tensor_input_shape(x_test_jkr)\n",
    "y_test_t_jkr = torch.from_numpy(y_test_jkr).type(torch.float)\n",
    "print(f\"Shape of the test tensors (x, y): {x_test_t_jkr.shape, y_test_t_jkr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the split outputs (train, valid): ((28333,), (5667,))\n",
      "Shape of the training and validation folds: ((28333, 9), (5667, 9))\n",
      "Shape of the training arrays (x, y): ((28333, 2), (28333, 2))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisr\\OneDrive\\Ambiente de Trabalho\\Tese\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=6.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training tensors (x, y): (torch.Size([28333, 50, 2]), torch.Size([28333, 2]))\n"
     ]
    }
   ],
   "source": [
    "# Do this for each fold in the CV loop\n",
    "train_idx, test_idx = next(skf.split(train_df_jkr, train_df_jkr['combined_targets']))\n",
    "print(f\"Shape of the split outputs (train, valid): {train_idx.shape, test_idx.shape}\")\n",
    "train_data = train_df_jkr.iloc[train_idx]\n",
    "valid_data = train_df_jkr.iloc[test_idx]\n",
    "print(f\"Shape of the training and validation folds: {train_data.shape, valid_data.shape}\")\n",
    "x_train = np.array(train_data[['withdraw_contact', 'f_jkr_contact']])\n",
    "y_train = np.array(train_data[['E_jkr', 'gamma_jkr']])\n",
    "print(f\"Shape of the training arrays (x, y): {x_train.shape, y_train.shape}\")\n",
    "x_train_t = tensor_input_shape(x_train)\n",
    "y_train_t = torch.from_numpy(y_train).type(torch.float)\n",
    "print(f\"Shape of the training tensors (x, y): {x_train_t.shape, y_train_t.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize target stratification in all folds\n",
    "\n",
    "# Create subplots\n",
    "list_of_arrays = valid_list\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Flatten the axes array to iterate over it easily\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through each array in the list\n",
    "for i, (array, ax) in enumerate(zip(list_of_arrays, axes)):\n",
    "\n",
    "    # Extract the third or fourth columns of the array\n",
    "    col_idx = 3\n",
    "    third_column = array[:, col_idx]\n",
    "\n",
    "    # Plot histogram\n",
    "    ax.hist(third_column, bins=20, edgecolor='black')\n",
    "    ax.set_title(f'Fold {i + 1}')\n",
    "    if col_idx == 2:\n",
    "        ax.set_ylim(0, 550)\n",
    "        ax.set_xlabel('$E$ (kPa)')\n",
    "    else:\n",
    "        ax.set_ylim(0, 400)\n",
    "        ax.set_xlabel('$\\gamma$')\n",
    "\n",
    "    ax.set_ylabel('Counts')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "def create_model_dir(timestamp, contact_model: str):\n",
    "\n",
    "  ''' Second input must be 'hertz' or 'jkr' '''\n",
    "  \n",
    "  allowed_models = ['hertz', 'jkr']\n",
    "  if contact_model not in allowed_models:\n",
    "    raise ValueError(\"Input value must be one of %s\" % allowed_models)\n",
    "  model_path = 'model_{}'.format(timestamp)\n",
    "  parent_dir = 'c:\\\\Users\\\\luisr\\\\OneDrive\\\\Ambiente de Trabalho\\\\Tese'\n",
    "  if contact_model == 'hertz':\n",
    "    dir = 'Hertz_models'\n",
    "  elif contact_model == 'jkr':\n",
    "    dir = 'JKR_models'\n",
    "  path = os.path.join(parent_dir, dir, model_path)\n",
    "  # path = os.path.join(initial_wd, dir, model_path)\n",
    "  os.mkdir(path)\n",
    "  os.chdir(path)\n",
    "\n",
    "def data_as_pkl(dataset_list: list):\n",
    "  file_names = ['x_train', 'y_train', 'x_valid', 'y_valid', 'x_test', 'y_test']\n",
    "  new_dir = 'Train_Validation_Data'\n",
    "  current_path = os.getcwd()\n",
    "  os.mkdir(new_dir)\n",
    "  os.chdir(new_dir)\n",
    "  for i, array in enumerate(dataset_list):\n",
    "    with open(file_names[i]+'.pkl', 'wb') as f:\n",
    "      pickle.dump(array, f)\n",
    "  os.chdir(current_path)\n",
    "\n",
    "def plot_loss_curve2(epochs, mse_training, mse_validation, loss: bool, E:bool, gamma:bool):\n",
    "  plt.ioff()\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  if loss:\n",
    "    if E:\n",
    "      plt.title(\"$E$\", fontsize=16)\n",
    "    elif gamma:\n",
    "      plt.title(\"$\\gamma$\", fontsize=16)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(epochs[0:], mse_training[0:], label=\"Training Loss\")\n",
    "    plt.plot(epochs[0:], mse_validation[0:], label=\"Validation Loss\")\n",
    "  else:\n",
    "    if E:\n",
    "      plt.title(\"$E$\", fontsize=16)\n",
    "    elif gamma:\n",
    "      plt.title(\"$\\gamma$\", fontsize=16)\n",
    "    plt.ylabel(\"Error (\\%)\")\n",
    "    plt.plot(epochs[0:], mse_training[0:], label=\"Training Error\")\n",
    "    plt.plot(epochs[0:], mse_validation[0:], label=\"Validation Error\")    \n",
    "  plt.legend()\n",
    "  # We're not going to plot the first epoch (>>greater loss)\n",
    "  merged_mse_lists = mse_training[1:] + mse_validation[1:]\n",
    "  highest_loss = max(merged_mse_lists)\n",
    "  lowest_loss = min(merged_mse_lists)\n",
    "  delta = highest_loss - lowest_loss\n",
    "  top_of_y_axis = highest_loss + (delta * 0.2)\n",
    "  bottom_of_y_axis = lowest_loss - (delta * 0.2)   \n",
    "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
    "  if loss:\n",
    "    if E:\n",
    "      plt.savefig('loss_plot_E.pdf')\n",
    "    elif gamma:\n",
    "      plt.savefig('loss_plot_gamma.pdf')\n",
    "    else:\n",
    "      plt.savefig('loss_plot.pdf') \n",
    "  else:\n",
    "    if E:\n",
    "      plt.savefig('error_plot_E.pdf')\n",
    "    elif gamma:\n",
    "      plt.savefig('error_plot_gamma.pdf')\n",
    "  # plt.show()\n",
    "  plt.close()\n",
    "\n",
    "\n",
    "def plot_bad_curves2(verror_list_E, verror_list_gamma, list_inputs, list_labels, test: bool):\n",
    "  plt.ioff()\n",
    "  verror_arr_E = np.array(verror_list_E)\n",
    "  verror_arr_gamma = np.array(verror_list_gamma)\n",
    "  v_error_arr = np.vstack((verror_arr_E, verror_arr_gamma)).T\n",
    "  bad_curves = [(i, j) for i, j in enumerate(v_error_arr) if j[0] > 15 and j[1] > 15] # Gets index and error value of all errors above 15%\n",
    "  if len(bad_curves) > 5:\n",
    "    bad_curves = sorted(bad_curves, key= lambda k:max(k[1]), reverse=True)[:5]\n",
    "  if len(bad_curves) < 5: \n",
    "    all_curves_sorted = sorted([(i, j) for i, j in enumerate(v_error_arr)], key= lambda k:max(k[1]), reverse=True) # sorts error list, keeping i (the original index of each error value)\n",
    "    for i in range(5-len(bad_curves)):\n",
    "        bad_curves.append(all_curves_sorted[len(bad_curves)+i])\n",
    "  plt.figure()\n",
    "  for j, (i, _) in enumerate(bad_curves):\n",
    "      tensor_idx = i//len(list_inputs[0])\n",
    "      tensor_fts, tensor_labels = list_inputs[tensor_idx], list_labels[tensor_idx]\n",
    "      plt.plot(tensor_fts[i-tensor_idx*len(list_inputs[0]),:,0].numpy(),\n",
    "              tensor_fts[i-tensor_idx*len(list_inputs[0]),:,1].numpy(),\n",
    "              alpha=0.75,\n",
    "              label=f'$E$={round(tensor_labels[i-tensor_idx*len(list_inputs[0]),0].item(),2)} kPa, $\\epsilon_E$={verror_list_E[i]: .1f}\\%, '+\n",
    "                    f'$\\gamma$={round(tensor_labels[i-tensor_idx*len(list_inputs[0]),1].item(),2)} $\\mu$J/m$^2$, $\\epsilon_\\gamma$={verror_list_gamma[i]: .1f}\\%')\n",
    "  plt.xlabel('Indentation (nm)')\n",
    "  plt.ylabel('Force (nN)')\n",
    "  plt.legend()\n",
    "  ax = plt.axis()\n",
    "  plt.axis((ax[1],ax[0],ax[2],ax[3]))\n",
    "  if test:\n",
    "    plt.savefig('bad_curves_test.pdf')\n",
    "  else:\n",
    "    plt.savefig('bad_curves_valid.pdf')\n",
    "  plt.close()\n",
    "\n",
    "def plot_error_hist2(error_list, test: bool, E:bool, **kwargs):\n",
    "  '''**kwargs: percentage of curves with errors under x%. \n",
    "              The values must be provided for errors in ascending order (error2_5 = y, error10 = z)'''\n",
    "  plt.ioff()\n",
    "  # Define variable name to be introduced in the file name of the final plots\n",
    "  if E:\n",
    "    var_name = 'E'\n",
    "  else:\n",
    "    var_name = 'gamma'\n",
    "  fig, ax = plt.subplots()\n",
    "  plt.figure()\n",
    "  x_values = [1, 2.5]\n",
    "  error_values = list(kwargs.values())\n",
    "  ax.hist(error_list, bins=20, density=True, ec='black', range=(0,6)) # to remove outliers, set parameter 'range='\n",
    "  if E:\n",
    "    ax.set_title(\"$E$\", fontsize=16, y=1.08)\n",
    "    ax.set_xlabel(\"Error $E$ (\\%)\")\n",
    "  else:\n",
    "    ax.set_title(\"$\\gamma$\", fontsize=16, y=1.08)\n",
    "    ax.set_xlabel(\"Error $\\gamma$ (\\%)\")\n",
    "  ax.set_ylabel(\"Density\")\n",
    "  #plt.gca().yaxis.set_major_formatter(PercentFormatter(1)) # set y axis as %\n",
    "  ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "  if test:\n",
    "    ax.axvline(x_values[0], color='red', linestyle='--', label=f'{error_values[0]*100: .1f}\\% of curves with $\\epsilon<1\\%$')\n",
    "    ax.axvline(x_values[1], color='green', linestyle='--', label=f'{error_values[1]*100: .1f}\\% of curves with $\\epsilon<2.5\\%$')\n",
    "    ax.legend(loc='center', ncol=2, bbox_to_anchor=(0.5, 1.05))\n",
    "    ax.text(0.74, 0.93, f'Synthetic test set ($n=$ {len(error_list)})', transform=ax.transAxes, fontsize=12, ha='center', bbox=dict(boxstyle='round', facecolor='white', edgecolor='black'))\n",
    "    # ax.set_title(\"Test error\")\n",
    "    fig.savefig(f'error_hist_test_{var_name}.pdf')\n",
    "  else:\n",
    "    fig.savefig(f'error_hist_valid_{var_name}.pdf') \n",
    "  # plt.show()\n",
    "  plt.close(fig)\n",
    "\n",
    "def plot_pred_real_curves2(verror_list_E, verror_list_gamma, list_inputs, list_labels, test: bool, list_predicts, nu, r, E:bool):\n",
    "  ''' Takes the list of errors and plots the curves with errors above 15%, and close to 10% and 2.5%.\n",
    "      If plotting E, the list of errors for E is used, and only curves with gamma error below 2% are considered (and vice-versa).\n",
    "      Inputs:\n",
    "        - verror_list_E: list of errors for E \n",
    "        - verror_list_gamma: list of errors for gamma\n",
    "        - list_inputs: list of tensors with inputs\n",
    "        - list_labels: list of tensors with labels\n",
    "        - test: boolean, True if test set, False if validation set\n",
    "        - list_predicts: list of tensors with predictions\n",
    "        - nu: Poisson's ratio\n",
    "        - r: radius of the tip\n",
    "        - E: boolean, True if plotting E, False if plotting gamma  \n",
    "  '''\n",
    "  plt.ioff()\n",
    "  if E:\n",
    "    var_name = 'E'\n",
    "    idx = 0\n",
    "    verror_list = verror_list_E\n",
    "    verror_list2 = verror_list_gamma\n",
    "  else:\n",
    "    var_name = 'gamma'\n",
    "    idx = 1\n",
    "    verror_list = verror_list_gamma\n",
    "    verror_list2 = verror_list_E\n",
    "  # Get all index of the values in verror_list2 that are below 2%\n",
    "  good_curves_2 = [i for i, j in enumerate(verror_list2) if j < 2.5]\n",
    "  # Select the curves in verror_list with index i in good_curves_2\n",
    "  verror_list = [verror_list[i] for i in good_curves_2]\n",
    "  bad_curves = []\n",
    "  bad_curves_15 = sorted([(i, j) for i, j in enumerate(verror_list) if j > 15], key= lambda k:k[1], reverse=True)\n",
    "  bad_curves_10 = sorted([(i, j) for i, j in enumerate(verror_list) if j < 10], key= lambda k:k[1], reverse=True)\n",
    "  bad_curves_2 = sorted([(i, j) for i, j in enumerate(verror_list) if j < 2], key= lambda k:k[1], reverse=True)\n",
    "  all_bad_curves = [bad_curves_15, bad_curves_10, bad_curves_2]\n",
    "  for curve in all_bad_curves:\n",
    "    if len(curve) >=1:\n",
    "      bad_curves.append(curve[0])\n",
    "  # plt.figure()\n",
    "  fig, ax = plt.subplots()\n",
    "  colors = ['red','blue', 'green']\n",
    "  line_styles = ['-', ':']\n",
    "  for j, (i, _) in enumerate(bad_curves):\n",
    "    tensor_idx = i//len(list_inputs[0])\n",
    "    tensor_fts, tensor_labels, tensor_predicts = list_inputs[tensor_idx], list_labels[tensor_idx], list_predicts[tensor_idx]\n",
    "    x = tensor_fts[i-tensor_idx*len(list_inputs[0]),:,0].numpy()\n",
    "    y1 = tensor_fts[i-tensor_idx*len(list_inputs[0]),:,1].numpy()\n",
    "    predict = tensor_predicts[i-tensor_idx*len(list_inputs[0]), idx].item()\n",
    "    y2 = hertz(x, predict, nu, r)\n",
    "    if E:\n",
    "      ax.set_title(\"$E$\", fontsize=16)\n",
    "      ax.plot(x,\n",
    "              y1,\n",
    "              alpha=0.75,\n",
    "              label='$E_{Real}$'+f'={round(tensor_labels[i-tensor_idx*len(list_inputs[0]), 0].item(),3)} kPa, $\\epsilon_E$={verror_list[i]: .2f} \\%',\n",
    "              color=colors[j], linestyle=line_styles[0])\n",
    "    else:\n",
    "      ax.set_title(\"$\\gamma$\", fontsize=16)\n",
    "      ax.plot(x,\n",
    "              y1,\n",
    "              alpha=0.75,\n",
    "              label='$\\gamma_{Real}$'+f'={round(tensor_labels[i-tensor_idx*len(list_inputs[0]), 1].item(),3)} $\\mu$J/m$^2$, $\\epsilon_\\gamma$={verror_list[i]: .2f} \\%',\n",
    "              color=colors[j], linestyle=line_styles[0])\n",
    "    ax.plot(x,\n",
    "             y2,\n",
    "             color=colors[j], linestyle=line_styles[1])\n",
    "    color_legend = ax.legend()\n",
    "  dummy_lines = []\n",
    "  for k in range(2):\n",
    "      dummy_lines.append(ax.plot([],[], c=\"black\", ls = line_styles[k])[0])\n",
    "  bbox_y = [0.85, 0.79, 0.73]\n",
    "  linestyle_legend = plt.legend([dummy_lines[i] for i in [0,1]], [\"Real curve\", \"Predicted Curve\"], loc=7, bbox_to_anchor=(1.,bbox_y[len(bad_curves)-1]))\n",
    "  # line_legend = ax.legend(loc='right')\n",
    "  plt.xlabel('Indentation (nm)')\n",
    "  plt.ylabel('Force (nN)')\n",
    "  # plt.legend()\n",
    "  ax.add_artist(color_legend)\n",
    "  ax.add_artist(linestyle_legend)\n",
    "  # put the legends in separate boxes\n",
    "  color_legend.get_frame().set_facecolor('white')\n",
    "  color_legend.get_frame().set_edgecolor('black')\n",
    "  linestyle_legend.get_frame().set_facecolor('white')\n",
    "  linestyle_legend.get_frame().set_edgecolor('black')\n",
    "  # ax.add_artist(line_legend)\n",
    "  ax2 = ax.axis()\n",
    "  ax.axis((ax2[1],ax2[0],ax2[2],ax2[3]))\n",
    "  if test:\n",
    "      fig.savefig(f'test_pred_vs_real_curves_{var_name}.pdf')\n",
    "  else:\n",
    "      fig.savefig(f'valid_pred_vs_real_curves_{var_name}.pdf')\n",
    "  plt.close(fig)\n",
    "\n",
    "def error_fn(predict_tensor, label_tensor):\n",
    "  '''\n",
    "  INPUTS: * two tensors - true labels and predicts\n",
    "  OUTPUTS: * scalar - mean relative error (in %) between both tensors\n",
    "           * list - relative error (%) for each prediction\n",
    "  '''\n",
    "  error = abs((label_tensor-predict_tensor)/label_tensor*100).squeeze(dim=1).mean().item()\n",
    "  error_list = list(abs((label_tensor-predict_tensor)/label_tensor*100).squeeze(dim=1).detach().numpy())\n",
    "  return error, error_list\n",
    "\n",
    "def scatter_true_pred(list_labels, list_preds, set: int, E: bool):\n",
    "  '''Scatter plot of model predictions vs true outputs around a unitary slope line\n",
    "    list_labels and list_preds: lists of one-valued tensors\n",
    "    set: 0 - Validation, 1 - Test synthetic, 2 - Test experimental\n",
    "    E: True if the Young's modulus is the variable being plotted'''\n",
    "  plt.ioff()\n",
    "  idx = 0 if E else 1\n",
    "  if set == 2:\n",
    "    labels_array = np.array([tensor.item() for tensor in list_labels])\n",
    "    predicts_array = np.array([tensor.item() for tensor in list_preds])\n",
    "  else:\n",
    "    labels_array = list_labels[0][:,idx].detach().numpy()\n",
    "    predicts_array = list_preds[0][:,idx].detach().numpy()     \n",
    "  sets = ['valid', 'test_syn', 'test_exp']\n",
    "  x = np.linspace(0,10.2,100)\n",
    "  plt.plot(x,x, color='orange', linewidth=2, label=\"Ideal predictions\",  alpha=0.8)\n",
    "  plt.scatter(labels_array, predicts_array, alpha=0.5, edgecolors='black', label=f\"Observations ($n =$ {len(labels_array)})\")\n",
    "  plt.legend(fontsize=14)\n",
    "  if E:\n",
    "    plt.xlabel(\"True $E$ (kPa)\")\n",
    "    plt.ylabel(\"Predicted $E$ (kPa)\")\n",
    "    plt.xlim(0,10.2)\n",
    "    plt.ylim(0,10.2)\n",
    "    plt.savefig('scatter_E_' + sets[set] + '.pdf', bbox_inches='tight')\n",
    "  else:\n",
    "    plt.xlabel(\"True $\\gamma$ ($\\mu$J/m$^2$)\")\n",
    "    plt.ylabel(\"Predicted $\\gamma$ ($\\mu$J/m$^2$)\")\n",
    "    plt.xlim(0.8,3.2)\n",
    "    plt.ylim(0.8,3.2)    \n",
    "    plt.savefig('scatter_gamma_' + sets[set] + '.pdf', bbox_inches='tight')\n",
    "  plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JKR_Dataset():\n",
    "  def __init__(self,features,labels):\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.features[idx],self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataloader\n",
    "test_data = JKR_Dataset(x_test_t_jkr, y_test_t_jkr)\n",
    "test_loader=DataLoader(test_data, batch_size=len(test_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ After changing one of the hyperparameters: ########################\n",
    "### Re-run the cells where the model class and the model_params dict are defined ###\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "LEARNING_RATE = 2.99e-4 # 2.99e-4\n",
    "EPOCHS = 110 # 110\n",
    "BATCH_SIZE = 16 # 16\n",
    "\n",
    "# Size of each layer\n",
    "HIDDEN_UNITS_1 = 128 # 256\n",
    "HIDDEN_UNITS_2 = 32 # 256\n",
    "HIDDEN_UNITS_3 = 128 # 32\n",
    "\n",
    "# 1: 2 layers, 2: 3 layers\n",
    "ARCHITECTURE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataloader(dataset, train_ids, test_ids):\n",
    "    train_data = dataset.iloc[train_ids]\n",
    "    valid_data = dataset.iloc[test_ids]\n",
    "    x_train = np.array(train_data[['withdraw_contact', 'f_jkr_contact']])\n",
    "    y_train = np.array(train_data[['E_jkr', 'gamma_jkr']])\n",
    "    x_valid = np.array(valid_data[['withdraw_contact', 'f_jkr_contact']])\n",
    "    y_valid = np.array(valid_data[['E_jkr', 'gamma_jkr']])\n",
    "    x_train_t = tensor_input_shape(x_train)\n",
    "    y_train_t = torch.from_numpy(y_train).type(torch.float)\n",
    "    x_valid_t = tensor_input_shape(x_valid)\n",
    "    y_valid_t = torch.from_numpy(y_valid).type(torch.float)\n",
    "    train_data = JKR_Dataset(x_train_t, y_train_t)\n",
    "    valid_data = JKR_Dataset(x_valid_t, y_valid_t)\n",
    "    train_loader=DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=False)\n",
    "    valid_loader=DataLoader(valid_data, batch_size=len(valid_data), shuffle=False)\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regression model\n",
    "class Regression_JKR(nn.Module):\n",
    "        def __init__(self, input_shape, HIDDEN_UNITS_1_JKR, HIDDEN_UNITS_2_JKR, HIDDEN_UNITS_3_JKR):\n",
    "            super(Regression_JKR, self).__init__()\n",
    "            input_size = input_shape[0] * input_shape[1]\n",
    "            self.layers = nn.Sequential(nn.Flatten(),\n",
    "                                        nn.Linear(input_size, HIDDEN_UNITS_1_JKR),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(HIDDEN_UNITS_1_JKR,HIDDEN_UNITS_2_JKR),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(HIDDEN_UNITS_2_JKR,HIDDEN_UNITS_3_JKR),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(HIDDEN_UNITS_3_JKR, 2))\n",
    "        def forward(self, x):\n",
    "            out = self.layers(x)\n",
    "            return out\n",
    "    \n",
    "# Define input shape\n",
    "input_shape = x_train_t.shape[1:]\n",
    "# Instantiate the model (add these two lines at the beggining of each fold cycle)\n",
    "torch.manual_seed(42)\n",
    "model_jkr = Regression_JKR(input_shape, HIDDEN_UNITS_1, HIDDEN_UNITS_2, HIDDEN_UNITS_3)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model_jkr.parameters(), \n",
    "                            lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Epochs': 110,\n",
       " 'Learning Rate': 0.000299,\n",
       " 'Batch Size': 16,\n",
       " 'Number of Hidden layers': 3,\n",
       " 'Type of layers': torch.nn.modules.linear.Linear,\n",
       " 'Activation function': LeakyReLU(negative_slope=0.01),\n",
       " 'Architecture': 2,\n",
       " 'Hidden Units 1': 128,\n",
       " 'Hidden Units 2': 32,\n",
       " 'Hidden Units 3': 128,\n",
       " 'Input shape': [50, 2],\n",
       " 'Loss function': MSELoss(),\n",
       " 'Optimizer': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.000299\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " )}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params_jkr = {'Epochs': EPOCHS, \n",
    "                'Learning Rate': LEARNING_RATE,\n",
    "                'Batch Size': BATCH_SIZE,\n",
    "                'Number of Hidden layers': 3,\n",
    "                'Type of layers': nn.Linear,\n",
    "                'Activation function': nn.LeakyReLU(),\n",
    "                'Architecture': ARCHITECTURE,\n",
    "                'Hidden Units 1': HIDDEN_UNITS_1,\n",
    "                'Hidden Units 2': HIDDEN_UNITS_2,\n",
    "                'Hidden Units 3': HIDDEN_UNITS_3,\n",
    "                'Input shape': list(input_shape),\n",
    "                'Loss function': loss_fn,\n",
    "                'Optimizer': optimizer}\n",
    "model_params_jkr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_jkr(epoch_index, train_loader, optimizer): # (epoch_index, tb_writer)\n",
    "    # running_loss = 0.\n",
    "    # last_loss = 0.\n",
    "    loss_list = []\n",
    "    error_E_list = []\n",
    "    error_gamma_list = []\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        predicts = model_jkr(inputs)\n",
    "        # print(predicts)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(predicts, labels).mean(dim=0)\n",
    "        error_E, _ = error_fn(predicts[:,0].unsqueeze(dim=1), labels[:,0].unsqueeze(dim=1))\n",
    "        error_gamma, _ = error_fn(predicts[:,1].unsqueeze(dim=1), labels[:,1].unsqueeze(dim=1))\n",
    "        loss.backward(gradient=torch.Tensor([1., 1.]))\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        # Gather data and report\n",
    "        loss_list.append(loss.detach().numpy())\n",
    "        error_E_list.append(error_E)\n",
    "        error_gamma_list.append(error_gamma)\n",
    "        # running_loss += loss.item()  # .item() converts tensor to number\n",
    "        # print(i, loss.item())\n",
    "    return loss_list, error_E_list, error_gamma_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_JKR(EPOCHS: int,\n",
    "                      model,\n",
    "                      tloader,\n",
    "                      vloader,\n",
    "                      loss_fn,\n",
    "                      optimizer,\n",
    "                      x_test_t, y_test_t,\n",
    "                      model_params_jkr: dict,\n",
    "                      ):\n",
    "    plt.ioff()\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    # Set new directory for new model\n",
    "    # initial_wd = os.getcwd()\n",
    "    create_model_dir(timestamp, contact_model='jkr')\n",
    "\n",
    "    best_vloss = 1e15\n",
    "    cols = ['Epoch', 'Train Loss', 'Mean Train Loss', 'Mean Val Loss', \n",
    "            'E - Train loss', 'E - Val loss','E - Train Error (%)', 'E - Mean Train Error (%)', 'E - Mean Val Error (%)', \n",
    "            'gamma - Train loss', 'gamma - Val loss','gamma - Train Error (%)', 'gamma - Mean Train Error (%)', 'gamma - Mean Val Error (%)']\n",
    "    row = []\n",
    "    # start timer counter\n",
    "    start = datetime.now()\n",
    "    for epoch in range(EPOCHS):\n",
    "        # print(f'Epoch {epoch+1} of {EPOCHS}')\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        loss_list, error_E_list, error_gamma_list = train_one_epoch_jkr(epoch, tloader, optimizer) # loss_list is a np array\n",
    "        loss_E = np.array(loss_list)[:,0].mean()\n",
    "        loss_gamma = np.array(loss_list)[:,1].mean()\n",
    "        # We don't need gradients on to do reporting\n",
    "        model.train(False)\n",
    "        running_vloss, running_verror_E, running_verror_gamma = 0.0, 0.0, 0.0\n",
    "        running_vloss_E, running_vloss_gamma = 0.0, 0.0\n",
    "        verror_E_list, verror_gamma_list, fts_list, labels_list, predicts_list = [], [], [], [], []\n",
    "        # Validation cycle\n",
    "        for i, vdata in enumerate(vloader):\n",
    "            vinputs, vlabels = vdata\n",
    "            fts_list.append(vinputs)\n",
    "            labels_list.append(vlabels)\n",
    "            voutputs = model(vinputs)\n",
    "            predicts_list.append(voutputs)\n",
    "            vloss = loss_fn(voutputs, vlabels).mean(dim=0)\n",
    "            vloss_E = vloss[0].item()\n",
    "            vloss_gamma = vloss[1].item()       \n",
    "            verror_E, verror_E_aux_list = error_fn(voutputs[:,0].unsqueeze(dim=1), vlabels[:,0].unsqueeze(dim=1))\n",
    "            verror_gamma, verror_gamma_aux_list = error_fn(voutputs[:,1].unsqueeze(dim=1), vlabels[:,1].unsqueeze(dim=1))\n",
    "            running_vloss += vloss.detach().mean().item()\n",
    "            running_vloss_E += vloss_E\n",
    "            running_vloss_gamma += vloss_gamma\n",
    "            running_verror_E += verror_E\n",
    "            running_verror_gamma += verror_gamma\n",
    "            verror_E_list += verror_E_aux_list\n",
    "            verror_gamma_list += verror_gamma_aux_list\n",
    "        \n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        avg_vloss_E = running_vloss_E / (i + 1)\n",
    "        avg_vloss_gamma = running_vloss_gamma / (i + 1)\n",
    "        verror_list = [verror_E_list, verror_gamma_list]\n",
    "        avg_verror_E = running_verror_E / (i + 1)\n",
    "        avg_verror_gamma = running_verror_gamma / (i + 1)\n",
    "        row.append(dict(zip(cols, \n",
    "                            [epoch+1, loss_list, np.array(loss_list).mean(), avg_vloss, \n",
    "                            loss_E, avg_vloss_E, error_E_list, np.array(error_E_list).mean(), avg_verror_E,\n",
    "                            loss_gamma, avg_vloss_gamma, error_gamma_list, np.array(error_gamma_list).mean(), avg_verror_gamma])))\n",
    "        # print(avg_verror_E, avg_verror_gamma, avg_vloss, loss_E)\n",
    "        # print(error_E_list, error_gamma_list)\n",
    "        # Track best performance\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            best_verror_E = avg_verror_E\n",
    "            best_verror_gamma = avg_verror_gamma\n",
    "            model_path = 'model_state_dict_{}_{}.pt'.format(timestamp, epoch+1)\n",
    "            verror_E_list_best = verror_E_list\n",
    "            verror_gamma_list_best = verror_gamma_list\n",
    "            fts_list_best = fts_list\n",
    "            labels_list_best = labels_list\n",
    "            predicts_list_best = predicts_list\n",
    "    end = datetime.now()\n",
    "    model_params_jkr['Training Time'] = end - start\n",
    "    print('Training time: {}'.format(model_params_jkr['Training Time']))\n",
    "    print(f\"Validation error - E (%): {best_verror_E}\")\n",
    "    print(f\"Validation error - gamma (%): {best_verror_gamma}\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    model_params_jkr['Model Path'] = model_path\n",
    "    df = pd.DataFrame(row)\n",
    "    df.to_csv('loss_error.csv', index=False)\n",
    "    # plot_loss_curve2(df['Epoch'].values.tolist(), df['Mean Train Loss'].values.tolist(), df['Mean Val Loss'].values.tolist(), loss=True, E=False, gamma=False)\n",
    "    # plot_loss_curve2(df['Epoch'].values.tolist(), df['E - Train loss'].values.tolist(), df['E - Val loss'].values.tolist(), loss=True, E=True, gamma=False)\n",
    "    # plot_loss_curve2(df['Epoch'].values.tolist(), df['gamma - Train loss'].values.tolist(), df['gamma - Val loss'].values.tolist(), loss=True, E=False, gamma=True)\n",
    "    # plot_loss_curve2(df['Epoch'].values.tolist(), df['E - Mean Train Error (%)'].values.tolist(), df['E - Mean Val Error (%)'].values.tolist(), loss=False, E=True, gamma=False)\n",
    "    # plot_loss_curve2(df['Epoch'].values.tolist(), df['gamma - Mean Train Error (%)'].values.tolist(), df['gamma - Mean Val Error (%)'].values.tolist(), loss=False, E=False, gamma=True)\n",
    "    # plot_bad_curves2(verror_E_list_best, verror_gamma_list_best, fts_list_best, labels_list_best, test=False)\n",
    "    # plot_error_hist2(verror_E_list_best, test=False, E=True)\n",
    "    # plot_error_hist2(verror_gamma_list_best, test=False, E=False)\n",
    "    scatter_true_pred(labels_list_best, predicts_list_best, set = 0, E = True)\n",
    "    scatter_true_pred(labels_list_best, predicts_list_best, set = 0, E = False)\n",
    "    with open('model_params.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = model_params_jkr.keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerow(model_params_jkr)\n",
    "    print(x_test_t.shape, y_test_t.shape)\n",
    "    torch.save(x_test_t, 'x_test_t.pt')\n",
    "    torch.save(y_test_t, 'y_test_t.pt')\n",
    "    # os.chdir(initial_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model: nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: nn.Module,\n",
    "               error_fn):\n",
    "    plt.ioff()\n",
    "    model.eval()\n",
    "    loss, loss_E, loss_gamma, error_E, error_gamma, avg_loss  = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    error_E_list, error_gamma_list, fts_list, labels_list, predicts_list = [], [], [], [], []\n",
    "    with torch.inference_mode():\n",
    "        for i, testdata in enumerate(data_loader):\n",
    "            test_fts, test_labels = testdata\n",
    "            fts_list.append(test_fts)\n",
    "            labels_list.append(test_labels)\n",
    "            y_pred = model(test_fts)\n",
    "            predicts_list.append(y_pred)\n",
    "            # LOSS \n",
    "            loss = loss_fn(y_pred, test_labels).mean(dim=0)\n",
    "            loss_E += loss[0].item()\n",
    "            loss_gamma += loss[1].item()\n",
    "            avg_loss += loss.mean().item()\n",
    "            # ERROR\n",
    "            error_E_aux, error_E_aux_list = error_fn(y_pred[:,0].unsqueeze(dim=1), test_labels[:,0].unsqueeze(dim=1))\n",
    "            error_gamma_aux, error_gamma_aux_list = error_fn(y_pred[:,1].unsqueeze(dim=1), test_labels[:,1].unsqueeze(dim=1)) ########\n",
    "            error_E += error_E_aux\n",
    "            error_gamma += error_gamma_aux\n",
    "            error_E_list += error_E_aux_list\n",
    "            error_gamma_list += error_gamma_aux_list\n",
    "        avg_loss /= len(data_loader)\n",
    "        loss_E /= len(data_loader)\n",
    "        loss_gamma /= len(data_loader)\n",
    "        error_E /= len(data_loader)\n",
    "        error_gamma /= len(data_loader)\n",
    "    np.save('error_list_E_test_syn.npy', np.array(error_E_list))\n",
    "    error1_E = len([i for i in error_E_list if i <= 1])/len(error_E_list)\n",
    "    error2_5_E = len([i for i in error_E_list if i <= 2.5])/len(error_E_list)\n",
    "    error5_E = len([i for i in error_E_list if i <= 5])/len(error_E_list)\n",
    "    error10_E = len([i for i in error_E_list if i <= 10])/len(error_E_list)\n",
    "    np.save('error_list_gamma_test_syn.npy', np.array(error_gamma_list))\n",
    "    error1_gamma = len([i for i in error_gamma_list if i <= 1])/len(error_gamma_list)\n",
    "    error2_5_gamma = len([i for i in error_gamma_list if i <= 2.5])/len(error_gamma_list)\n",
    "    error5_gamma = len([i for i in error_gamma_list if i <= 5])/len(error_gamma_list)\n",
    "    error10_gamma = len([i for i in error_gamma_list if i <= 10])/len(error_gamma_list)\n",
    "    print(f\"Test Error - E (%): {error_E}\")\n",
    "    print(f\"Test Curves under 5% - E (%): {error5_E*100}\")\n",
    "    print(f\"Test Error - gamma (%): {error_gamma}\")\n",
    "    print(f\"Test Curves under 5% - gamma (%): {error5_gamma*100}\")\n",
    "    results_dict_E = {\"model_name\": model.__class__.__name__,\n",
    "                    \"model_loss\": loss_E,\n",
    "                    \"model_error\": error_E,\n",
    "                    \"under_1%_error\": error1_E,\n",
    "                    \"under_2.5%_error\": error2_5_E,\n",
    "                    \"under_5%_error\": error5_E,\n",
    "                    \"under_10%_error\": error10_E}\n",
    "    \n",
    "    results_dict_gamma = {\"model_name\": model.__class__.__name__,\n",
    "                        \"model_loss\": loss_gamma,\n",
    "                        \"model_error\": error_gamma,\n",
    "                        \"under_1%_error\": error1_gamma,\n",
    "                        \"under_2.5%_error\": error2_5_gamma,\n",
    "                        \"under_5%_error\": error5_gamma,\n",
    "                        \"under_10%_error\": error10_gamma}\n",
    "    \n",
    "    with open('test_results_E.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = results_dict_E.keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerow(results_dict_E)\n",
    "    with open('test_results_gamma.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = results_dict_gamma.keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerow(results_dict_gamma)\n",
    "        \n",
    "    plot_error_hist2(error_E_list, test=True, E=True, error1=error1_E, error2=error2_5_E)\n",
    "    plot_error_hist2(error_gamma_list, test=True, E=False, error1=error1_gamma, error2=error2_5_gamma)\n",
    "    plot_bad_curves2(error_E_list, error_gamma_list, fts_list, labels_list, test=True)\n",
    "    plot_pred_real_curves2(error_E_list, error_gamma_list, fts_list, labels_list, test=True, list_predicts=predicts_list, nu=nu, r=r, E=True)\n",
    "    plot_pred_real_curves2(error_E_list, error_gamma_list, fts_list, labels_list, test=True, list_predicts=predicts_list, nu=nu, r=r, E=False)\n",
    "    scatter_true_pred(labels_list, predicts_list, set = 1, E = True)\n",
    "    scatter_true_pred(labels_list, predicts_list, set = 1, E = False)\n",
    "    print(results_dict_E)\n",
    "    print(results_dict_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "FOLD 5\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisr\\OneDrive\\Ambiente de Trabalho\\Tese\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=6.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Training time: 0:08:17.712866\n",
      "Validation error - E (%): 0.5426933169364929\n",
      "Validation error - gamma (%): 1.0025688409805298\n",
      "torch.Size([6000, 50, 2]) torch.Size([6000, 2])\n",
      "Testing on synthetic data...\n",
      "Test Error - E (%): 0.49504733085632324\n",
      "Test Curves under 5% - E (%): 99.5\n",
      "Test Error - gamma (%): 1.366005539894104\n",
      "Test Curves under 5% - gamma (%): 98.26666666666667\n",
      "{'model_name': 'Regression_JKR', 'model_loss': 0.0003979377797804773, 'model_error': 0.49504733085632324, 'under_1%_error': 0.8935, 'under_2.5%_error': 0.9791666666666666, 'under_5%_error': 0.995, 'under_10%_error': 0.9991666666666666}\n",
      "{'model_name': 'Regression_JKR', 'model_loss': 0.001038929563947022, 'model_error': 1.366005539894104, 'under_1%_error': 0.4685, 'under_2.5%_error': 0.8653333333333333, 'under_5%_error': 0.9826666666666667, 'under_10%_error': 0.9986666666666667}\n",
      "--------------------------------\n",
      "FOLD 6\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Perform Cross-Validation ()\n",
    "plt.ioff() # Turn off plotting display\n",
    "k_folds = 6\n",
    "\n",
    "# Stratified K-fold cross validator\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=False, random_state=None)\n",
    "\n",
    "# Start print\n",
    "print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for fold, (train_ids, valid_ids) in enumerate(skf.split(train_df_jkr, train_df_jkr['combined_targets'])):\n",
    "    os.chdir(initial_wd)\n",
    "    # Prints\n",
    "    print(f'FOLD {fold+1}')\n",
    "    print('--------------------------------')\n",
    "    if fold == 4:\n",
    "        # Dataset and DataLoader stuff\n",
    "        train_loader, valid_loader = prep_dataloader(dataset=train_df_jkr, train_ids=train_ids, test_ids=valid_ids)            \n",
    "\n",
    "        # Initialize the NN\n",
    "        input_shape = x_train_t.shape[1:]\n",
    "        torch.manual_seed(42)\n",
    "        model_jkr = Regression_JKR(input_shape, HIDDEN_UNITS_1, HIDDEN_UNITS_2, HIDDEN_UNITS_3)\n",
    "        optimizer = torch.optim.Adam(model_jkr.parameters(), \n",
    "                                lr=LEARNING_RATE)\n",
    "        # Start Training + Validation\n",
    "        print(\"Training ...\")\n",
    "        plt.ioff()\n",
    "        train_model_JKR(EPOCHS, model_jkr, train_loader, valid_loader, loss_fn, optimizer, x_test_t_jkr, y_test_t_jkr, model_params_jkr)\n",
    "        \n",
    "        # Start testing\n",
    "        print(\"Testing on synthetic data...\")\n",
    "        eval_model(model_jkr, test_loader, loss_fn, error_fn)\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\luisr\\\\OneDrive\\\\Ambiente de Trabalho\\\\Tese\\\\contact-surface'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(initial_wd)\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
